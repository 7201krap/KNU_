{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cf52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7949486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "import time \n",
    "from gym.envs.registration import register\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43831bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "        id='FrozenLakeNoSlip-v0',\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name' : '4x4', 'is_slippery':False},\n",
    "        max_episode_steps=100,\n",
    "        reward_threshold=0.78, # optimum = .8196\n",
    "        ) \n",
    "\n",
    "# env_name = \"CartPole-v1\"\n",
    "# env_name = \"MountainCar-v0\"\n",
    "# env_name = \"MountainCarContinuous-v0\"\n",
    "# env_name = \"Acrobot-v1\"\n",
    "# env_name = \"Pendulum-v1\"\n",
    "# env_name = \"FrozenLake-v1\"\n",
    "env_name = \"FrozenLakeNoSlip-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cfe09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space -> Discrete(16)\n",
      "Action space -> Discrete(4)\n",
      "Type of action -> <class 'gym.spaces.discrete.Discrete'>\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "print(\"Observation space ->\", env.observation_space)\n",
    "print(\"Action space ->\", env.action_space)\n",
    "print(\"Type of action ->\", type(env.action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f0501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    '''\n",
    "    1. Model이 discrete한지 continuous한지 판단하고, state_size를 저장한다.\n",
    "    2. discrete일 경우, action_size를 저장. \n",
    "    3. continuous일 경우, action의 boundary와 shape을 저장.\n",
    "    '''\n",
    "    def __init__(self, env):\n",
    "        self.is_discrete = \\\n",
    "            type(env.action_space) == gym.spaces.discrete.Discrete\n",
    "        \n",
    "        # state_size == state의 갯수 \n",
    "        self.state_size = env.observation_space.n\n",
    "        print(\"State size:\", self.state_size)\n",
    "        \n",
    "        if self.is_discrete:\n",
    "            # action_size == action의 갯수 \n",
    "            self.action_size = env.action_space.n\n",
    "            print(\"Environment is Discrete and Action size is\", self.action_size)\n",
    "  \n",
    "        else:\n",
    "            print(\"Environment is Continuous\")\n",
    "            \n",
    "            # action의 boundary와 action의 shape\n",
    "            self.action_low = env.action_space.low \n",
    "            self.action_high = env.action_space.high\n",
    "            self.action_shape = env.action_space.shape\n",
    "            print(\"self.action_low ->\", self.action_low)\n",
    "            print(\"self.action_high ->\", self.action_high)\n",
    "            print(\"self.action_shape ->\", self.action_shape)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Returns a randomly selected action\n",
    "        '''\n",
    "        if self.is_discrete:\n",
    "            action = random.choice(range(self.action_size))\n",
    "        else:\n",
    "            action = np.random.uniform(self.action_low,\n",
    "                                       self.action_high,\n",
    "                                       self.action_shape)\n",
    "            \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e19fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSA_Agent(Agent):\n",
    "    def __init__(self, env, discount_rate=0.97, learning_rate=0.01):\n",
    "        super().__init__(env)\n",
    "        \n",
    "        self.eps = 1.0\n",
    "        self.discount_rate = discount_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.build_model()\n",
    "        \n",
    "        print(\"discount_rate:\", discount_rate)\n",
    "        print(\"learning_rate:\", learning_rate)\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.SARSA_table = 1e-4*np.random.random([self.state_size, self.action_size])\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        SARSA_current = self.SARSA_table[state]\n",
    "        action_greedy = np.argmax(SARSA_current)\n",
    "        action_random = super().get_action(state)\n",
    "        \n",
    "        # Decaying epsilon algorithm. Decay a chance of having the random action for every episode.\n",
    "        if random.random() < self.eps:\n",
    "            return action_random \n",
    "        else:\n",
    "            return action_greedy\n",
    "    \n",
    "    def train(self, experience):\n",
    "        state, action, reward, next_state, next_action, done = experience\n",
    "        \n",
    "        SARSA_next = self.SARSA_table[next_state]\n",
    "        \n",
    "        if done:\n",
    "            SARSA_next = np.zeros([self.action_size])\n",
    "\n",
    "        self.SARSA_table[state, action] = (1 - self.learning_rate) * self.SARSA_table[state, action] + \\\n",
    "        self.learning_rate * (reward + self.discount_rate * self.SARSA_table[next_state, next_action])\n",
    "        \n",
    "        if done:\n",
    "            # decay epsilon. \n",
    "            self.eps = self.eps * 0.99 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c409312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:1 -> A:1 -> R:0.0 -> S:5 -> A:2. Done? True\n",
      "Episode: 999, Total reward: 4.0, eps: 4.317124741065784e-05\n",
      "---------------------------------------------------------------------\n",
      "<SARSA table>\n",
      " [[5.73958225e-05 4.15122495e-05 7.19714329e-05 4.73513648e-05]\n",
      " [5.35622911e-05 7.42169489e-05 7.31219995e-05 7.31178370e-05]\n",
      " [7.43081271e-05 3.69992296e-05 1.49089330e-05 8.82296675e-06]\n",
      " [9.33140976e-05 9.33499702e-05 6.26955125e-05 4.06926195e-05]\n",
      " [5.98733605e-05 7.75799980e-05 7.46553294e-05 6.28469851e-05]\n",
      " [7.17901242e-05 4.91919093e-05 7.65169270e-05 3.98873360e-05]\n",
      " [2.40631363e-05 1.27293482e-05 9.12048003e-05 8.71494047e-05]\n",
      " [9.01111528e-05 6.61716956e-05 1.44486585e-05 2.14635580e-05]\n",
      " [1.22380949e-05 9.11451934e-05 1.21498944e-05 1.31297842e-05]\n",
      " [3.26777147e-05 8.75380235e-05 8.79034156e-06 7.43527467e-05]\n",
      " [9.31171371e-05 4.10898925e-05 4.71742224e-06 5.16414550e-05]\n",
      " [6.51605191e-05 7.34293728e-06 8.89673462e-05 7.80293435e-05]\n",
      " [2.04249425e-05 8.70220657e-05 2.11084054e-05 4.58650985e-05]\n",
      " [8.26640844e-05 7.62664223e-06 5.93548951e-04 8.66377729e-05]\n",
      " [7.28882400e-06 7.77002206e-05 3.94672804e-02 6.67368504e-05]\n",
      " [2.46665314e-05 5.13241375e-05 2.89914103e-05 9.38323818e-05]]\n",
      "---------------------------------------------------------------------\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# Generate an agent that follows SARSA-Learning algorithm.\n",
    "SARSA_agent = SARSA_Agent(env)\n",
    "total_reward = 0\n",
    "total_reward_list = list()\n",
    "episodes = 1000\n",
    "\n",
    "for episode in range(episodes):\n",
    "    \n",
    "    total_reward_list.append(total_reward)\n",
    "    state = env.reset() # reset the environment when the episode terminates\n",
    "    \n",
    "    print(f\"Entering Episode {episode}\")\n",
    "    print(f\"Total Reward is {total_reward}\")\n",
    "#     time.sleep(0.25)\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    SARSA_action = SARSA_agent.get_action(state)\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        next_state, reward, done, info = env.step(SARSA_action)\n",
    "        \n",
    "        SARSA_next_action = SARSA_agent.get_action(next_state)\n",
    "        \n",
    "        # save the agent's experience as a tuple\n",
    "        experience = (state, SARSA_action, reward, next_state, SARSA_next_action, done)\n",
    "        print(f\"S:{state} -> A:{SARSA_action} -> R:{reward} -> S:{next_state} -> A:{SARSA_next_action}. Done? {done}\")\n",
    "\n",
    "        # train my SARSA_agent\n",
    "        SARSA_agent.train(experience)\n",
    "        \n",
    "        # The agent moves to the next state\n",
    "        state = next_state\n",
    "        \n",
    "        SARSA_action = SARSA_next_action\n",
    "        \n",
    "        # accumulate reward\n",
    "        total_reward = total_reward + reward\n",
    "        \n",
    "        print(f\"Episode: {episode}, Total reward: {total_reward}, eps: {SARSA_agent.eps}\")\n",
    "        print(\"---------------------------------------------------------------------\")\n",
    "        print(f\"<SARSA table>\\n\", SARSA_agent.SARSA_table)\n",
    "        print(\"---------------------------------------------------------------------\")\n",
    "        \n",
    "        env.render()\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "#         time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47975cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_tool(episode_length, total_reward):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.linspace(0, episode_length, num=episode_length)\n",
    "    y = total_reward \n",
    "    \n",
    "    ax.plot(x, y)\n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.set_ylabel('Total Reward')\n",
    "    \n",
    "    ax.set_ylim(0, episode_length)\n",
    "    ax.set_title('Accumulated Total Rewards')\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7734f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_tool(episodes, total_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b648d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32edee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9afe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a44052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca08579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70103b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73548b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
