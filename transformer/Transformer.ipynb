{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPmuAQVp2WX4tSniLJ8vZoL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":33,"metadata":{"id":"aZzXST8gRacG","executionInfo":{"status":"ok","timestamp":1645517087150,"user_tz":-540,"elapsed":520,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","from prettytable import PrettyTable"]},{"cell_type":"code","source":["def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad: continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params+=params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params"],"metadata":{"id":"Cf6ZYhi_Zk9H","executionInfo":{"status":"ok","timestamp":1645517087735,"user_tz":-540,"elapsed":8,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["class SelfAttention(nn.Module):\n","    def __init__(self, embed_size, heads):\n","        super(SelfAttention, self).__init__()\n","        self.embed_size = embed_size\n","        self.heads = heads\n","        self.head_dim = embed_size // heads\n","\n","        assert (\n","            self.head_dim * heads == embed_size\n","        ), \"Embedding size needs to be divisible by heads\"\n","\n","        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)  # W^O matrix \n","\n","    def forward(self, values, keys, query, mask):\n","        # Get number of training examples\n","        N = query.shape[0]\n","\n","        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n","\n","        # Split the embedding into self.heads different pieces\n","        values = values.reshape(N, value_len, self.heads, self.head_dim)\n","        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n","        query = query.reshape(N, query_len, self.heads, self.head_dim)\n","\n","        values = self.values(values)  # (N, value_len, heads, head_dim)\n","        keys = self.keys(keys)  # (N, key_len, heads, head_dim)\n","        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n","\n","        # Einsum does matrix mult. for query*keys for each training example\n","        # with every other training example, don't be confused by einsum\n","        # it's just how I like doing matrix multiplication & bmm\n","\n","        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n","        # queries shape: (N, query_len, heads, heads_dim),\n","        # keys shape: (N, key_len, heads, heads_dim)\n","        # energy: (N, heads, query_len, key_len)\n","\n","        # Mask padded indices so their weights become 0\n","        if mask is not None:\n","            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n","\n","        # Normalize energy values similarly to seq2seq + attention\n","        # so that they sum to 1. Also divide by scaling factor for\n","        # better stability\n","        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n","        # attention shape: (N, heads, query_len, key_len)\n","\n","        # Concatenation\n","        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n","            N, query_len, self.heads * self.head_dim\n","        )\n","        # attention shape: (N, heads, query_len, key_len)\n","        # values shape: (N, value_len, heads, heads_dim)\n","        # out after matrix multiply: (N, query_len, heads, head_dim), then\n","        # we reshape and flatten the last two dimensions.\n","\n","        out = self.fc_out(out)\n","        # Linear layer doesn't modify the shape, final shape will be\n","        # (N, query_len, embed_size)\n","\n","        # Output of the multi-head self-attention\n","        return out"],"metadata":{"id":"WsLlSs-HS0ZN","executionInfo":{"status":"ok","timestamp":1645517087737,"user_tz":-540,"elapsed":8,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, embed_size, heads, dropout, forward_expansion):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = SelfAttention(embed_size, heads)\n","        self.norm1 = nn.LayerNorm(embed_size)\n","        self.norm2 = nn.LayerNorm(embed_size)\n","\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(embed_size, forward_expansion * embed_size),\n","            nn.ReLU(),\n","            nn.Linear(forward_expansion * embed_size, embed_size),\n","        )\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, value, key, query, mask):\n","        attention = self.attention(value, key, query, mask)\n","\n","        # Add skip connection, run through normalization and finally dropout\n","        # x = self.dropout( LayerNorm(Sublayer(x) + x) )\n","\n","        x = self.norm1(attention + query)\n","\n","        print(\"Value after normalisation. (Before FF)\")\n","        print(x)\n","\n","        x = self.dropout(x)\n","\n","        forward = self.feed_forward(x)\n","\n","        x = self.norm2(forward + x)\n","\n","        print(\"Value after normalisation. (After FF)\")\n","        print(x)\n","\n","        out = self.dropout(x)\n","\n","        return out"],"metadata":{"id":"9WuJehAqXon_","executionInfo":{"status":"ok","timestamp":1645517087738,"user_tz":-540,"elapsed":8,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size,\n","        embed_size,\n","        num_layers,\n","        heads,\n","        device,\n","        forward_expansion,\n","        dropout,\n","        max_length,\n","    ):\n","\n","        super(Encoder, self).__init__()\n","        self.embed_size = embed_size\n","        self.device = device\n","        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_length, embed_size)\n","\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerBlock(\n","                    embed_size,\n","                    heads,\n","                    dropout=dropout,\n","                    forward_expansion=forward_expansion,\n","                )\n","                for _ in range(num_layers)\n","            ]\n","        )\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.encoder_layer_counter = 0\n","\n","    def forward(self, x, mask):\n","        N, seq_length = x.shape\n","        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","        out = self.dropout(\n","            (self.word_embedding(x) + self.position_embedding(positions))\n","        )\n","\n","        # In the Encoder the query, key, value are all the same, it's in the\n","        # decoder this will change. This might look a bit odd in this case.\n","        # The last Encoder output is the same as the final Encoder output\n","        for layer in self.layers:\n","            self.encoder_layer_counter = self.encoder_layer_counter + 1\n","            out = layer(out, out, out, mask)\n","            print(f\"{self.encoder_layer_counter}-th Encoder output is {out}\")\n","\n","        print(\"<Encoder out shape>\\n\", out.shape)\n","        print(\"<Encoder out>\\n\", out)    \n","        print(\"================================================================\")\n","\n","        return out"],"metadata":{"id":"O8iP_hHsXqBP","executionInfo":{"status":"ok","timestamp":1645517088196,"user_tz":-540,"elapsed":8,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["class DecoderBlock(nn.Module):\n","    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n","        super(DecoderBlock, self).__init__()\n","        self.norm = nn.LayerNorm(embed_size)\n","        self.attention = SelfAttention(embed_size, heads=heads)\n","        self.transformer_block = TransformerBlock(\n","            embed_size, heads, dropout, forward_expansion\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, value, key, src_mask, trg_mask):\n","        attention = self.attention(x, x, x, trg_mask)\n","        query = self.dropout(self.norm(attention + x))\n","        out = self.transformer_block(value, key, query, src_mask)\n","        return out\n"],"metadata":{"id":"BbTLWdrnXrlf","executionInfo":{"status":"ok","timestamp":1645517088198,"user_tz":-540,"elapsed":9,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(\n","        self,\n","        trg_vocab_size,\n","        embed_size,\n","        num_layers,\n","        heads,\n","        forward_expansion,\n","        dropout,\n","        device,\n","        max_length,\n","    ):\n","        super(Decoder, self).__init__()\n","        self.device = device\n","        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_length, embed_size)\n","\n","        self.layers = nn.ModuleList(\n","            [\n","                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n","                for _ in range(num_layers)\n","            ]\n","        )\n","        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.decoder_layer_counter = 0 \n","\n","    def forward(self, x, enc_out, src_mask, trg_mask):\n","        N, seq_length = x.shape\n","        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n","\n","        for layer in self.layers:\n","            self.decoder_layer_counter = self.decoder_layer_counter + 1\n","            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n","            print(\"Shape of Decoder output\", x.shape)\n","            print(f\"{self.decoder_layer_counter}-th Decoder output is {x}\")\n","        \n","        out = self.fc_out(x)\n","\n","        print(\"\\n<Output of decoder after applying Linear layer>\\n\")\n","        print(\"Decoder out.shape\", out.shape)\n","        print(\"Decoder out\", out)\n","\n","        return out\n"],"metadata":{"id":"iykmMdkzXtNu","executionInfo":{"status":"ok","timestamp":1645517088199,"user_tz":-540,"elapsed":9,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size,\n","        trg_vocab_size,\n","        src_pad_idx,\n","        trg_pad_idx,\n","        embed_size=512,\n","        num_layers=6,\n","        forward_expansion=4,\n","        heads=8,\n","        dropout=0,\n","        device=\"cpu\",\n","        max_length=100,\n","    ):\n","\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(\n","            src_vocab_size,\n","            embed_size,\n","            num_layers,\n","            heads,\n","            device,\n","            forward_expansion,\n","            dropout,\n","            max_length,\n","        )\n","\n","        self.decoder = Decoder(\n","            trg_vocab_size,\n","            embed_size,\n","            num_layers,\n","            heads,\n","            forward_expansion,\n","            dropout,\n","            device,\n","            max_length,\n","        )\n","\n","        self.src_pad_idx = src_pad_idx\n","        self.trg_pad_idx = trg_pad_idx\n","        self.device = device\n","\n","    def make_src_mask(self, src):\n","        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n","        # (N, 1, 1, src_len)\n","        return src_mask.to(self.device)\n","\n","    def make_trg_mask(self, trg):\n","        N, trg_len = trg.shape\n","        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n","            N, 1, trg_len, trg_len\n","        )\n","\n","        return trg_mask.to(self.device)\n","\n","    def forward(self, src, trg):\n","        src_mask = self.make_src_mask(src)\n","        trg_mask = self.make_trg_mask(trg)\n","        enc_src = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n","        return out\n"],"metadata":{"id":"JX1YDxzQXupX","executionInfo":{"status":"ok","timestamp":1645517088200,"user_tz":-540,"elapsed":9,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    print(\"=============================== main started ===============================\")\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","\n","    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2], [1, 8, 7, 3, 4, 5, 6, 7]]).to(\n","        device\n","    )\n","\n","    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n","\n","    src_pad_idx = 0\n","    trg_pad_idx = 0\n","    src_vocab_size = 10\n","    trg_vocab_size = 10\n","\n","    model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(\n","        device\n","    )\n","\n","    out = model(x, trg)\n","\n","    print(\"\\n<Output of decoder after applying Linear layer>\\n\")\n","    print(out.shape)\n","    print(out)\n","\n","    print(\"=============================== main done ===============================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cls5ondVXwle","executionInfo":{"status":"ok","timestamp":1645517088819,"user_tz":-540,"elapsed":14,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"05d8e733-a645-4103-ab4e-2ee11382f3f6"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["=============================== main started ===============================\n","cpu\n","Value after normalisation. (Before FF)\n","tensor([[[ 0.1560, -0.3566,  1.2330,  ...,  1.6240,  1.0576,  0.8888],\n","         [-0.7901, -0.4820,  1.3944,  ...,  1.4702, -0.1224,  0.9340],\n","         [-0.2097, -0.4023, -1.6194,  ..., -0.8245, -0.4463, -2.0399],\n","         ...,\n","         [ 0.4298, -0.3077, -0.1539,  ..., -0.3422, -1.0317, -0.3408],\n","         [ 0.8044,  0.5168,  2.2114,  ..., -0.3697, -0.7543, -0.1361],\n","         [-1.5110,  0.8067, -1.7293,  ...,  1.4637, -0.4376,  0.0859]],\n","\n","        [[ 0.1244, -0.3457,  1.2885,  ...,  1.7708,  1.1376,  0.8630],\n","         [-0.8464, -0.3012, -0.7076,  ..., -0.2684, -0.2277,  2.4080],\n","         [ 1.0087, -0.6809, -0.2126,  ...,  0.3562, -0.4049, -0.4209],\n","         ...,\n","         [ 0.7371, -0.5263,  1.9929,  ...,  0.4190, -0.3427,  0.1182],\n","         [ 0.3449,  0.0600,  0.3378,  ..., -1.7634, -1.4093, -0.7624],\n","         [ 0.6100, -0.0232,  0.6457,  ...,  2.0002, -0.7560,  1.3350]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 1.4503e-01, -3.1483e-01,  1.5968e+00,  ...,  1.5974e+00,\n","           1.1728e+00,  8.0221e-01],\n","         [-6.4157e-01, -6.5536e-01,  1.0756e+00,  ...,  1.5042e+00,\n","          -2.8730e-02,  9.8350e-01],\n","         [-2.1826e-01, -5.0672e-01, -1.5480e+00,  ..., -5.8400e-01,\n","          -1.5482e-01, -1.9848e+00],\n","         ...,\n","         [ 3.9148e-01, -2.9927e-01, -3.6072e-01,  ..., -4.4488e-01,\n","          -9.2187e-01, -3.8202e-01],\n","         [ 1.0219e+00,  5.1392e-01,  1.8985e+00,  ..., -5.0459e-01,\n","          -5.4466e-01,  9.7451e-02],\n","         [-1.4326e+00,  2.9425e-01, -1.7637e+00,  ...,  1.4577e+00,\n","          -1.5442e-01,  5.1123e-01]],\n","\n","        [[ 1.1086e-01, -2.9088e-01,  1.6479e+00,  ...,  1.7303e+00,\n","           1.2323e+00,  7.4968e-01],\n","         [-5.3687e-01, -4.1304e-01, -9.8966e-01,  ..., -3.3789e-01,\n","           9.1250e-02,  2.6261e+00],\n","         [ 1.0304e+00, -7.6978e-01,  8.2899e-02,  ...,  6.9297e-02,\n","           1.9641e-04, -1.9716e-01],\n","         ...,\n","         [ 1.0333e+00, -7.0861e-01,  1.8034e+00,  ...,  4.7963e-01,\n","          -2.1905e-01,  2.5424e-02],\n","         [ 3.0726e-01, -5.0618e-02,  7.9404e-02,  ..., -1.4451e+00,\n","          -1.2849e+00, -7.1729e-01],\n","         [ 8.9343e-01, -4.1256e-01,  7.5523e-01,  ...,  1.8346e+00,\n","          -3.9250e-01,  1.5018e+00]]], grad_fn=<NativeLayerNormBackward0>)\n","1-th Encoder output is tensor([[[ 1.4503e-01, -3.1483e-01,  1.5968e+00,  ...,  1.5974e+00,\n","           1.1728e+00,  8.0221e-01],\n","         [-6.4157e-01, -6.5536e-01,  1.0756e+00,  ...,  1.5042e+00,\n","          -2.8730e-02,  9.8350e-01],\n","         [-2.1826e-01, -5.0672e-01, -1.5480e+00,  ..., -5.8400e-01,\n","          -1.5482e-01, -1.9848e+00],\n","         ...,\n","         [ 3.9148e-01, -2.9927e-01, -3.6072e-01,  ..., -4.4488e-01,\n","          -9.2187e-01, -3.8202e-01],\n","         [ 1.0219e+00,  5.1392e-01,  1.8985e+00,  ..., -5.0459e-01,\n","          -5.4466e-01,  9.7451e-02],\n","         [-1.4326e+00,  2.9425e-01, -1.7637e+00,  ...,  1.4577e+00,\n","          -1.5442e-01,  5.1123e-01]],\n","\n","        [[ 1.1086e-01, -2.9088e-01,  1.6479e+00,  ...,  1.7303e+00,\n","           1.2323e+00,  7.4968e-01],\n","         [-5.3687e-01, -4.1304e-01, -9.8966e-01,  ..., -3.3789e-01,\n","           9.1250e-02,  2.6261e+00],\n","         [ 1.0304e+00, -7.6978e-01,  8.2899e-02,  ...,  6.9297e-02,\n","           1.9641e-04, -1.9716e-01],\n","         ...,\n","         [ 1.0333e+00, -7.0861e-01,  1.8034e+00,  ...,  4.7963e-01,\n","          -2.1905e-01,  2.5424e-02],\n","         [ 3.0726e-01, -5.0618e-02,  7.9404e-02,  ..., -1.4451e+00,\n","          -1.2849e+00, -7.1729e-01],\n","         [ 8.9343e-01, -4.1256e-01,  7.5523e-01,  ...,  1.8346e+00,\n","          -3.9250e-01,  1.5018e+00]]], grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 0.1485, -0.2117,  1.6427,  ...,  1.3917,  1.1379,  0.7552],\n","         [-0.6251, -0.5613,  1.1311,  ...,  1.3115, -0.0333,  0.9582],\n","         [-0.1977, -0.4037, -1.4687,  ..., -0.7683, -0.1683, -2.0264],\n","         ...,\n","         [ 0.3911, -0.2131, -0.2951,  ..., -0.6275, -0.9182, -0.4098],\n","         [ 1.0516,  0.6160,  1.9584,  ..., -0.7011, -0.5495,  0.0717],\n","         [-1.3757,  0.3863, -1.6817,  ...,  1.2592, -0.1673,  0.4850]],\n","\n","        [[ 0.2430, -0.2843,  1.6811,  ...,  1.6549,  1.1325,  0.6654],\n","         [-0.3951, -0.4011, -0.9199,  ..., -0.3919,  0.0324,  2.5042],\n","         [ 1.1448, -0.7624,  0.1337,  ...,  0.0144, -0.0732, -0.2790],\n","         ...,\n","         [ 1.1463, -0.7100,  1.8342,  ...,  0.4361, -0.3026, -0.0660],\n","         [ 0.4049, -0.0523,  0.1226,  ..., -1.4602, -1.3392, -0.8113],\n","         [ 1.0184, -0.4255,  0.7961,  ...,  1.7498, -0.4672,  1.3947]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 0.3067, -0.1875,  1.7678,  ...,  1.5456,  0.9970,  0.6752],\n","         [-0.6391, -0.2100,  0.8689,  ...,  1.5437,  0.1729,  0.9155],\n","         [-0.0582, -0.0041, -1.2994,  ..., -0.7278, -0.5382, -1.8876],\n","         ...,\n","         [ 0.5832, -0.0410, -0.4116,  ..., -0.8777, -0.6834,  0.2430],\n","         [ 1.0436,  0.9776,  1.6847,  ..., -0.4879, -0.7055,  0.1447],\n","         [-0.9377,  0.2330, -1.4315,  ...,  1.5333, -0.3338,  1.0456]],\n","\n","        [[ 0.4125, -0.2435,  1.7829,  ...,  1.7535,  0.9809,  0.5751],\n","         [-0.4222, -0.4186, -1.1090,  ..., -0.2961,  0.1209,  2.6842],\n","         [ 1.3990, -0.5925,  0.1334,  ..., -0.0679, -0.1304,  0.0274],\n","         ...,\n","         [ 1.0549, -0.6616,  1.8054,  ...,  0.4681,  0.1415,  0.2302],\n","         [ 0.4548,  0.3640,  0.0736,  ..., -1.2989, -1.7278, -0.9015],\n","         [ 1.1361, -0.5929,  0.7592,  ...,  1.7731, -0.3025,  1.8894]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","2-th Encoder output is tensor([[[ 0.3067, -0.1875,  1.7678,  ...,  1.5456,  0.9970,  0.6752],\n","         [-0.6391, -0.2100,  0.8689,  ...,  1.5437,  0.1729,  0.9155],\n","         [-0.0582, -0.0041, -1.2994,  ..., -0.7278, -0.5382, -1.8876],\n","         ...,\n","         [ 0.5832, -0.0410, -0.4116,  ..., -0.8777, -0.6834,  0.2430],\n","         [ 1.0436,  0.9776,  1.6847,  ..., -0.4879, -0.7055,  0.1447],\n","         [-0.9377,  0.2330, -1.4315,  ...,  1.5333, -0.3338,  1.0456]],\n","\n","        [[ 0.4125, -0.2435,  1.7829,  ...,  1.7535,  0.9809,  0.5751],\n","         [-0.4222, -0.4186, -1.1090,  ..., -0.2961,  0.1209,  2.6842],\n","         [ 1.3990, -0.5925,  0.1334,  ..., -0.0679, -0.1304,  0.0274],\n","         ...,\n","         [ 1.0549, -0.6616,  1.8054,  ...,  0.4681,  0.1415,  0.2302],\n","         [ 0.4548,  0.3640,  0.0736,  ..., -1.2989, -1.7278, -0.9015],\n","         [ 1.1361, -0.5929,  0.7592,  ...,  1.7731, -0.3025,  1.8894]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 0.4281, -0.1785,  1.8073,  ...,  1.6127,  1.0407,  0.7736],\n","         [-0.5103, -0.1944,  0.9354,  ...,  1.6098,  0.2356,  0.9866],\n","         [ 0.0860,  0.0150, -1.1789,  ..., -0.6251, -0.4576, -1.7536],\n","         ...,\n","         [ 0.7016, -0.0353, -0.3247,  ..., -0.7743, -0.6065,  0.3218],\n","         [ 1.1727,  0.9954,  1.7634,  ..., -0.3941, -0.6415,  0.2277],\n","         [-0.7944,  0.2511, -1.3267,  ...,  1.5884, -0.2636,  1.1245]],\n","\n","        [[ 0.4690, -0.1877,  1.8817,  ...,  1.8204,  1.1284,  0.5035],\n","         [-0.3482, -0.3628, -0.9363,  ..., -0.1805,  0.2953,  2.5200],\n","         [ 1.4397, -0.5329,  0.2465,  ...,  0.0497,  0.0272, -0.0526],\n","         ...,\n","         [ 1.1272, -0.6158,  1.9410,  ...,  0.5918,  0.3117,  0.1403],\n","         [ 0.5117,  0.4191,  0.2442,  ..., -1.1845, -1.5183, -0.9845],\n","         [ 1.1789, -0.5393,  0.8962,  ...,  1.8627, -0.1516,  1.8095]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 0.6654,  0.1010,  1.7246,  ...,  1.8741,  0.7978,  0.6772],\n","         [-0.2208, -0.2681,  0.7713,  ...,  1.6718,  0.2608,  0.7661],\n","         [ 0.2651, -0.1899, -1.3900,  ..., -0.5669, -1.0033, -1.7391],\n","         ...,\n","         [ 0.4932,  0.0646, -0.4814,  ..., -0.6086, -0.7677,  0.4347],\n","         [ 1.1352,  0.9713,  1.5267,  ..., -0.3835, -0.6932,  0.5266],\n","         [-0.7511, -0.0221, -1.5890,  ...,  1.6162, -0.4257,  1.3246]],\n","\n","        [[ 0.6992,  0.1036,  1.8182,  ...,  2.0716,  0.9254,  0.4158],\n","         [ 0.1432, -0.4778, -1.1723,  ..., -0.0664, -0.1319,  2.0634],\n","         [ 1.4406, -0.8337, -0.0878,  ...,  0.2255, -0.4520,  0.0488],\n","         ...,\n","         [ 0.9308, -0.7442,  1.6848,  ...,  0.7047,  0.3418,  0.2073],\n","         [ 0.7966,  0.4488,  0.0727,  ..., -1.0033, -1.8016, -0.7004],\n","         [ 1.0750, -0.9556,  0.6379,  ...,  1.9163, -0.3310,  1.9253]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","3-th Encoder output is tensor([[[ 0.6654,  0.1010,  1.7246,  ...,  1.8741,  0.7978,  0.6772],\n","         [-0.2208, -0.2681,  0.7713,  ...,  1.6718,  0.2608,  0.7661],\n","         [ 0.2651, -0.1899, -1.3900,  ..., -0.5669, -1.0033, -1.7391],\n","         ...,\n","         [ 0.4932,  0.0646, -0.4814,  ..., -0.6086, -0.7677,  0.4347],\n","         [ 1.1352,  0.9713,  1.5267,  ..., -0.3835, -0.6932,  0.5266],\n","         [-0.7511, -0.0221, -1.5890,  ...,  1.6162, -0.4257,  1.3246]],\n","\n","        [[ 0.6992,  0.1036,  1.8182,  ...,  2.0716,  0.9254,  0.4158],\n","         [ 0.1432, -0.4778, -1.1723,  ..., -0.0664, -0.1319,  2.0634],\n","         [ 1.4406, -0.8337, -0.0878,  ...,  0.2255, -0.4520,  0.0488],\n","         ...,\n","         [ 0.9308, -0.7442,  1.6848,  ...,  0.7047,  0.3418,  0.2073],\n","         [ 0.7966,  0.4488,  0.0727,  ..., -1.0033, -1.8016, -0.7004],\n","         [ 1.0750, -0.9556,  0.6379,  ...,  1.9163, -0.3310,  1.9253]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 0.8640,  0.0828,  1.3008,  ...,  1.8417,  0.7906,  0.5847],\n","         [-0.0241, -0.3015,  0.3418,  ...,  1.6321,  0.2726,  0.6555],\n","         [ 0.4547, -0.2244, -1.7886,  ..., -0.5976, -1.0019, -1.8024],\n","         ...,\n","         [ 0.6836,  0.0454, -0.8829,  ..., -0.5993, -0.7387,  0.3489],\n","         [ 1.3354,  0.9464,  1.1114,  ..., -0.4153, -0.6875,  0.4285],\n","         [-0.5181, -0.0478, -2.0066,  ...,  1.5746, -0.4273,  1.1915]],\n","\n","        [[ 1.0019, -0.0480,  1.3178,  ...,  1.9237,  1.0280,  0.1577],\n","         [ 0.4400, -0.6644, -1.6566,  ..., -0.1915, -0.0272,  1.7791],\n","         [ 1.7134, -0.9762, -0.5840,  ...,  0.0787, -0.3484, -0.2282],\n","         ...,\n","         [ 1.2275, -0.9144,  1.1789,  ...,  0.5591,  0.4241, -0.0476],\n","         [ 1.1033,  0.2793, -0.4024,  ..., -1.1359, -1.7098, -0.9853],\n","         [ 1.3692, -1.1108,  0.1252,  ...,  1.7461, -0.2304,  1.6155]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 0.6995,  0.2979,  1.1566,  ...,  1.8013,  0.8075,  0.5278],\n","         [-0.0413, -0.0491,  0.6131,  ...,  1.5304,  0.3684,  0.8575],\n","         [ 0.4048,  0.1213, -1.7922,  ..., -0.3611, -1.0200, -1.7187],\n","         ...,\n","         [-0.0153,  0.2000, -0.7577,  ..., -0.6422, -0.5168,  0.6342],\n","         [ 1.0735,  0.9297,  1.3723,  ..., -0.3623, -0.7826,  0.3615],\n","         [-0.6986, -0.0219, -1.8633,  ...,  1.7083, -0.6413,  1.5843]],\n","\n","        [[ 0.8517,  0.1515,  1.2270,  ...,  1.9165,  1.0106,  0.0986],\n","         [ 0.4835, -0.4042, -1.7464,  ..., -0.1467,  0.1493,  2.1608],\n","         [ 1.6423, -0.6778, -0.4409,  ..., -0.0403, -0.1243, -0.0068],\n","         ...,\n","         [ 0.8811, -0.7040,  1.6374,  ...,  0.4911,  0.4177,  0.0288],\n","         [ 1.0388,  0.1588, -0.7142,  ..., -1.0386, -1.8466, -0.7957],\n","         [ 1.2767, -1.1254,  0.0784,  ...,  1.8165, -0.3583,  2.0759]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","4-th Encoder output is tensor([[[ 0.6995,  0.2979,  1.1566,  ...,  1.8013,  0.8075,  0.5278],\n","         [-0.0413, -0.0491,  0.6131,  ...,  1.5304,  0.3684,  0.8575],\n","         [ 0.4048,  0.1213, -1.7922,  ..., -0.3611, -1.0200, -1.7187],\n","         ...,\n","         [-0.0153,  0.2000, -0.7577,  ..., -0.6422, -0.5168,  0.6342],\n","         [ 1.0735,  0.9297,  1.3723,  ..., -0.3623, -0.7826,  0.3615],\n","         [-0.6986, -0.0219, -1.8633,  ...,  1.7083, -0.6413,  1.5843]],\n","\n","        [[ 0.8517,  0.1515,  1.2270,  ...,  1.9165,  1.0106,  0.0986],\n","         [ 0.4835, -0.4042, -1.7464,  ..., -0.1467,  0.1493,  2.1608],\n","         [ 1.6423, -0.6778, -0.4409,  ..., -0.0403, -0.1243, -0.0068],\n","         ...,\n","         [ 0.8811, -0.7040,  1.6374,  ...,  0.4911,  0.4177,  0.0288],\n","         [ 1.0388,  0.1588, -0.7142,  ..., -1.0386, -1.8466, -0.7957],\n","         [ 1.2767, -1.1254,  0.0784,  ...,  1.8165, -0.3583,  2.0759]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 6.8048e-01,  2.0537e-01,  1.2081e+00,  ...,  1.9976e+00,\n","           7.4353e-01,  4.4728e-01],\n","         [-4.3598e-02, -1.3746e-01,  6.5628e-01,  ...,  1.6762e+00,\n","           3.1659e-01,  7.4632e-01],\n","         [ 3.8311e-01,  3.5091e-02, -1.6800e+00,  ..., -1.3065e-01,\n","          -1.0492e+00, -1.7981e+00],\n","         ...,\n","         [-4.3484e-02,  9.9831e-02, -6.7073e-01,  ..., -4.1511e-01,\n","          -5.5809e-01,  5.5686e-01],\n","         [ 1.0383e+00,  8.1158e-01,  1.3982e+00,  ..., -1.3805e-01,\n","          -8.0828e-01,  2.6127e-01],\n","         [-7.2230e-01, -9.5843e-02, -1.7672e+00,  ...,  1.9274e+00,\n","          -6.6417e-01,  1.4962e+00]],\n","\n","        [[ 8.0817e-01,  2.1929e-02,  1.1602e+00,  ...,  2.0594e+00,\n","           9.5866e-01,  1.4239e-01],\n","         [ 4.3634e-01, -5.0366e-01, -1.7565e+00,  ...,  1.3650e-02,\n","           1.1172e-01,  2.1377e+00],\n","         [ 1.5564e+00, -7.6895e-01, -4.6164e-01,  ...,  1.1321e-01,\n","          -1.6957e-01, -1.8494e-03],\n","         ...,\n","         [ 8.0791e-01, -8.2279e-01,  1.5533e+00,  ...,  6.3980e-01,\n","           3.5696e-01,  6.6160e-02],\n","         [ 9.8407e-01,  6.5458e-02, -7.4130e-01,  ..., -8.7848e-01,\n","          -1.8600e+00, -7.7201e-01],\n","         [ 1.1980e+00, -1.2122e+00,  5.3859e-02,  ...,  1.9377e+00,\n","          -3.7729e-01,  2.0554e+00]]], grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 0.5419,  0.2391,  1.1928,  ...,  1.9157,  1.0511,  0.4256],\n","         [-0.1403,  0.2340,  0.8722,  ...,  1.8341,  0.5736,  0.7552],\n","         [ 0.3282,  0.1241, -1.7339,  ..., -0.0324, -0.8885, -1.5212],\n","         ...,\n","         [ 0.0680,  0.2663, -0.5502,  ..., -0.6538, -0.4537,  0.7055],\n","         [ 0.9903,  0.9981,  1.8233,  ..., -0.1511, -1.0042,  0.4937],\n","         [-0.4641, -0.0431, -1.8599,  ...,  2.1020, -0.5659,  1.4553]],\n","\n","        [[ 0.6439,  0.1383,  1.0643,  ...,  1.9184,  1.2647,  0.1359],\n","         [ 0.5475, -0.1873, -1.6041,  ..., -0.1157,  0.1543,  2.1976],\n","         [ 1.2296, -0.4300, -0.4715,  ...,  0.2279, -0.1403,  0.0945],\n","         ...,\n","         [ 0.7831, -0.5138,  1.8087,  ...,  0.6786,  0.3967,  0.1135],\n","         [ 0.8440,  0.1735, -0.5446,  ..., -0.9805, -1.9988, -0.4658],\n","         [ 1.1006, -1.1602, -0.1876,  ...,  1.8258, -0.3118,  2.0417]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","5-th Encoder output is tensor([[[ 0.5419,  0.2391,  1.1928,  ...,  1.9157,  1.0511,  0.4256],\n","         [-0.1403,  0.2340,  0.8722,  ...,  1.8341,  0.5736,  0.7552],\n","         [ 0.3282,  0.1241, -1.7339,  ..., -0.0324, -0.8885, -1.5212],\n","         ...,\n","         [ 0.0680,  0.2663, -0.5502,  ..., -0.6538, -0.4537,  0.7055],\n","         [ 0.9903,  0.9981,  1.8233,  ..., -0.1511, -1.0042,  0.4937],\n","         [-0.4641, -0.0431, -1.8599,  ...,  2.1020, -0.5659,  1.4553]],\n","\n","        [[ 0.6439,  0.1383,  1.0643,  ...,  1.9184,  1.2647,  0.1359],\n","         [ 0.5475, -0.1873, -1.6041,  ..., -0.1157,  0.1543,  2.1976],\n","         [ 1.2296, -0.4300, -0.4715,  ...,  0.2279, -0.1403,  0.0945],\n","         ...,\n","         [ 0.7831, -0.5138,  1.8087,  ...,  0.6786,  0.3967,  0.1135],\n","         [ 0.8440,  0.1735, -0.5446,  ..., -0.9805, -1.9988, -0.4658],\n","         [ 1.1006, -1.1602, -0.1876,  ...,  1.8258, -0.3118,  2.0417]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 1.0610,  0.3010,  1.3450,  ...,  1.8150,  1.0419,  0.7207],\n","         [ 0.4164,  0.3153,  1.0309,  ...,  1.7762,  0.5478,  1.0466],\n","         [ 0.8431,  0.2050, -1.5093,  ..., -0.0486, -0.8691, -1.2042],\n","         ...,\n","         [ 0.6104,  0.3483, -0.3502,  ..., -0.6725, -0.4392,  1.0015],\n","         [ 1.5148,  1.0745,  1.9588,  ..., -0.1729, -0.9987,  0.7881],\n","         [ 0.0700,  0.0428, -1.6286,  ...,  2.0146, -0.5561,  1.7382]],\n","\n","        [[ 1.0154,  0.2965,  1.1357,  ...,  1.9779,  1.3057,  0.4080],\n","         [ 0.9355, -0.0328, -1.4626,  ...,  0.0208,  0.2311,  2.4320],\n","         [ 1.5721, -0.2499, -0.3576,  ...,  0.3241, -0.0614,  0.3727],\n","         ...,\n","         [ 1.1463, -0.3247,  1.8617,  ...,  0.7727,  0.4662,  0.3736],\n","         [ 1.2193,  0.3313, -0.4305,  ..., -0.8527, -1.8664, -0.1778],\n","         [ 1.4338, -0.9502, -0.0745,  ...,  1.8691, -0.2287,  2.2610]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 1.2663,  0.2333,  1.2869,  ...,  2.1595,  0.9647,  0.5199],\n","         [ 0.4960,  0.1910,  1.4870,  ...,  1.6208,  0.3379,  1.1051],\n","         [ 0.8362,  0.6475, -1.0289,  ..., -0.1039, -0.6181, -1.3304],\n","         ...,\n","         [ 0.7652,  0.3981, -0.0400,  ..., -0.7434, -0.3651,  0.9080],\n","         [ 1.5072,  1.0633,  1.9908,  ..., -0.2104, -0.8441,  0.7714],\n","         [ 0.1965,  0.0048, -1.0935,  ...,  1.9888, -0.6206,  1.7761]],\n","\n","        [[ 1.2157,  0.1699,  1.0297,  ...,  2.2517,  1.2925,  0.1953],\n","         [ 0.9212, -0.0182, -0.8149,  ..., -0.3450,  0.2699,  2.5669],\n","         [ 1.6259, -0.2313,  0.1812,  ...,  0.0471,  0.1083,  0.4720],\n","         ...,\n","         [ 1.2171, -0.3222,  2.0849,  ...,  0.5767,  0.5089,  0.3655],\n","         [ 1.1790,  0.5042, -0.2626,  ..., -0.8854, -1.6151, -0.1789],\n","         [ 1.7264, -0.9138,  0.5968,  ...,  1.5310, -0.4845,  2.4876]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","6-th Encoder output is tensor([[[ 1.2663,  0.2333,  1.2869,  ...,  2.1595,  0.9647,  0.5199],\n","         [ 0.4960,  0.1910,  1.4870,  ...,  1.6208,  0.3379,  1.1051],\n","         [ 0.8362,  0.6475, -1.0289,  ..., -0.1039, -0.6181, -1.3304],\n","         ...,\n","         [ 0.7652,  0.3981, -0.0400,  ..., -0.7434, -0.3651,  0.9080],\n","         [ 1.5072,  1.0633,  1.9908,  ..., -0.2104, -0.8441,  0.7714],\n","         [ 0.1965,  0.0048, -1.0935,  ...,  1.9888, -0.6206,  1.7761]],\n","\n","        [[ 1.2157,  0.1699,  1.0297,  ...,  2.2517,  1.2925,  0.1953],\n","         [ 0.9212, -0.0182, -0.8149,  ..., -0.3450,  0.2699,  2.5669],\n","         [ 1.6259, -0.2313,  0.1812,  ...,  0.0471,  0.1083,  0.4720],\n","         ...,\n","         [ 1.2171, -0.3222,  2.0849,  ...,  0.5767,  0.5089,  0.3655],\n","         [ 1.1790,  0.5042, -0.2626,  ..., -0.8854, -1.6151, -0.1789],\n","         [ 1.7264, -0.9138,  0.5968,  ...,  1.5310, -0.4845,  2.4876]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","<Encoder out shape>\n"," torch.Size([2, 8, 512])\n","<Encoder out>\n"," tensor([[[ 1.2663,  0.2333,  1.2869,  ...,  2.1595,  0.9647,  0.5199],\n","         [ 0.4960,  0.1910,  1.4870,  ...,  1.6208,  0.3379,  1.1051],\n","         [ 0.8362,  0.6475, -1.0289,  ..., -0.1039, -0.6181, -1.3304],\n","         ...,\n","         [ 0.7652,  0.3981, -0.0400,  ..., -0.7434, -0.3651,  0.9080],\n","         [ 1.5072,  1.0633,  1.9908,  ..., -0.2104, -0.8441,  0.7714],\n","         [ 0.1965,  0.0048, -1.0935,  ...,  1.9888, -0.6206,  1.7761]],\n","\n","        [[ 1.2157,  0.1699,  1.0297,  ...,  2.2517,  1.2925,  0.1953],\n","         [ 0.9212, -0.0182, -0.8149,  ..., -0.3450,  0.2699,  2.5669],\n","         [ 1.6259, -0.2313,  0.1812,  ...,  0.0471,  0.1083,  0.4720],\n","         ...,\n","         [ 1.2171, -0.3222,  2.0849,  ...,  0.5767,  0.5089,  0.3655],\n","         [ 1.1790,  0.5042, -0.2626,  ..., -0.8854, -1.6151, -0.1789],\n","         [ 1.7264, -0.9138,  0.5968,  ...,  1.5310, -0.4845,  2.4876]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","================================================================\n","Value after normalisation. (Before FF)\n","tensor([[[ 1.3677,  0.6830,  0.5823,  ...,  0.4259,  0.7493, -1.5323],\n","         [-0.3781,  0.3907, -1.9796,  ...,  1.0965, -0.2286,  0.8415],\n","         [-0.5860,  1.7667, -0.4767,  ..., -0.5784,  0.0679, -0.7325],\n","         ...,\n","         [-0.4069, -0.7071, -1.0960,  ...,  0.3527, -0.7181, -1.4125],\n","         [ 0.9738,  1.4042, -1.0136,  ..., -2.2443,  0.6367,  0.1248],\n","         [ 0.5137,  0.3272, -0.1775,  ...,  1.4646, -0.0484, -1.4660]],\n","\n","        [[ 1.3205,  0.7376,  0.6174,  ...,  0.3927,  0.6248, -1.4435],\n","         [-0.7855, -0.0128, -1.4131,  ...,  0.0437,  0.9597,  0.4646],\n","         [ 1.2139,  0.8630, -0.6071,  ...,  0.1729,  1.5649,  0.5841],\n","         ...,\n","         [ 0.2704,  0.2214, -0.4468,  ...,  0.1930, -0.8886, -0.2837],\n","         [ 2.1191,  0.9889, -1.5148,  ..., -0.7707,  1.6703,  0.4397],\n","         [ 0.0294,  0.9894, -0.8766,  ..., -0.9117,  0.1547,  0.1278]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 1.4952e+00,  1.3283e-01,  6.2118e-01,  ...,  6.4528e-01,\n","           7.6608e-01, -1.5066e+00],\n","         [-4.8864e-01,  1.9354e-01, -1.7321e+00,  ...,  1.0336e+00,\n","          -1.2463e-01,  1.1654e+00],\n","         [-5.5235e-01,  1.5945e+00, -4.0050e-01,  ..., -1.6803e-01,\n","           1.5080e-01, -1.3609e+00],\n","         ...,\n","         [-1.2403e-02, -7.5297e-01, -1.2894e+00,  ...,  3.1543e-01,\n","          -1.7995e-01, -1.6675e+00],\n","         [ 1.3775e+00,  1.4758e+00, -9.0208e-01,  ..., -2.2076e+00,\n","           1.0057e+00,  1.7294e-01],\n","         [ 3.5198e-01, -3.5083e-04, -3.4961e-01,  ...,  1.5188e+00,\n","          -2.0050e-01, -1.5538e+00]],\n","\n","        [[ 1.4503e+00,  1.7665e-01,  6.5033e-01,  ...,  6.1623e-01,\n","           6.6480e-01, -1.4142e+00],\n","         [-5.0669e-01, -2.9178e-01, -1.5279e+00,  ..., -2.1497e-01,\n","           1.3252e+00,  6.8970e-01],\n","         [ 1.1861e+00,  6.2385e-01, -8.4303e-01,  ...,  3.7244e-01,\n","           1.4487e+00,  1.7719e-01],\n","         ...,\n","         [ 4.6790e-01, -3.6661e-02, -2.5112e-01,  ...,  2.3986e-01,\n","          -7.2890e-01,  7.9556e-02],\n","         [ 2.4479e+00,  1.0928e+00, -2.0543e+00,  ..., -7.5652e-01,\n","           1.7569e+00,  3.1104e-01],\n","         [ 2.8968e-01,  1.1105e+00, -6.9529e-01,  ..., -1.0279e+00,\n","           3.6060e-01, -7.5093e-02]]], grad_fn=<NativeLayerNormBackward0>)\n","Shape of Decoder output torch.Size([2, 8, 512])\n","1-th Decoder output is tensor([[[ 1.4952e+00,  1.3283e-01,  6.2118e-01,  ...,  6.4528e-01,\n","           7.6608e-01, -1.5066e+00],\n","         [-4.8864e-01,  1.9354e-01, -1.7321e+00,  ...,  1.0336e+00,\n","          -1.2463e-01,  1.1654e+00],\n","         [-5.5235e-01,  1.5945e+00, -4.0050e-01,  ..., -1.6803e-01,\n","           1.5080e-01, -1.3609e+00],\n","         ...,\n","         [-1.2403e-02, -7.5297e-01, -1.2894e+00,  ...,  3.1543e-01,\n","          -1.7995e-01, -1.6675e+00],\n","         [ 1.3775e+00,  1.4758e+00, -9.0208e-01,  ..., -2.2076e+00,\n","           1.0057e+00,  1.7294e-01],\n","         [ 3.5198e-01, -3.5083e-04, -3.4961e-01,  ...,  1.5188e+00,\n","          -2.0050e-01, -1.5538e+00]],\n","\n","        [[ 1.4503e+00,  1.7665e-01,  6.5033e-01,  ...,  6.1623e-01,\n","           6.6480e-01, -1.4142e+00],\n","         [-5.0669e-01, -2.9178e-01, -1.5279e+00,  ..., -2.1497e-01,\n","           1.3252e+00,  6.8970e-01],\n","         [ 1.1861e+00,  6.2385e-01, -8.4303e-01,  ...,  3.7244e-01,\n","           1.4487e+00,  1.7719e-01],\n","         ...,\n","         [ 4.6790e-01, -3.6661e-02, -2.5112e-01,  ...,  2.3986e-01,\n","          -7.2890e-01,  7.9556e-02],\n","         [ 2.4479e+00,  1.0928e+00, -2.0543e+00,  ..., -7.5652e-01,\n","           1.7569e+00,  3.1104e-01],\n","         [ 2.8968e-01,  1.1105e+00, -6.9529e-01,  ..., -1.0279e+00,\n","           3.6060e-01, -7.5093e-02]]], grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 1.0647,  0.6874,  1.2184,  ...,  0.6262,  1.1383, -1.4465],\n","         [-0.8205,  0.6677, -1.4006,  ...,  0.9260,  0.0840,  1.1653],\n","         [-0.6891,  1.9123, -0.1840,  ..., -0.2831,  0.1861, -1.4398],\n","         ...,\n","         [-0.2631, -0.3918, -1.1003,  ...,  0.2434, -0.1315, -1.5676],\n","         [ 1.0493,  1.7075, -0.8048,  ..., -2.2656,  1.0233,  0.2396],\n","         [ 0.0976,  0.1937, -0.2096,  ...,  1.3739, -0.1703, -1.4652]],\n","\n","        [[ 1.0383,  0.7410,  1.2004,  ...,  0.5955,  1.0965, -1.2498],\n","         [-0.8135,  0.3459, -1.1551,  ..., -0.2867,  1.4325,  0.8566],\n","         [ 0.8933,  1.1717, -0.4848,  ...,  0.0943,  1.4810,  0.1412],\n","         ...,\n","         [ 0.0384,  0.3202, -0.2034,  ...,  0.0968, -0.6883,  0.1804],\n","         [ 1.9055,  1.3268, -1.9343,  ..., -0.9102,  1.7247,  0.3808],\n","         [-0.1277,  1.2634, -0.6367,  ..., -1.1489,  0.4187, -0.0186]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 0.8311,  0.7164,  1.3249,  ...,  0.5504,  1.0825, -1.5104],\n","         [-1.0437,  0.7128, -1.6843,  ...,  1.0755,  0.1046,  1.0352],\n","         [-0.8580,  1.6566, -0.0564,  ..., -0.1613,  0.4364, -1.6758],\n","         ...,\n","         [-0.4149, -0.7769, -1.0993,  ...,  0.3273,  0.0429, -1.7423],\n","         [ 0.7297,  1.7832, -1.0849,  ..., -2.4123,  0.8611,  0.3187],\n","         [ 0.2747,  0.1019, -0.3418,  ...,  1.4733, -0.3583, -1.4608]],\n","\n","        [[ 0.8397,  0.8029,  1.3402,  ...,  0.5085,  1.0457, -1.3230],\n","         [-0.8283,  0.4975, -1.2396,  ..., -0.2907,  1.2312,  0.6119],\n","         [ 0.6689,  0.8510, -0.4638,  ..., -0.1531,  1.4952, -0.2910],\n","         ...,\n","         [-0.2084,  0.0668, -0.3572,  ...,  0.1785, -0.5267,  0.1211],\n","         [ 1.8586,  1.0106, -2.0471,  ..., -1.5156,  1.4252,  0.3410],\n","         [-0.3483,  1.4775, -0.7931,  ..., -0.9105,  0.2251, -0.0111]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Shape of Decoder output torch.Size([2, 8, 512])\n","2-th Decoder output is tensor([[[ 0.8311,  0.7164,  1.3249,  ...,  0.5504,  1.0825, -1.5104],\n","         [-1.0437,  0.7128, -1.6843,  ...,  1.0755,  0.1046,  1.0352],\n","         [-0.8580,  1.6566, -0.0564,  ..., -0.1613,  0.4364, -1.6758],\n","         ...,\n","         [-0.4149, -0.7769, -1.0993,  ...,  0.3273,  0.0429, -1.7423],\n","         [ 0.7297,  1.7832, -1.0849,  ..., -2.4123,  0.8611,  0.3187],\n","         [ 0.2747,  0.1019, -0.3418,  ...,  1.4733, -0.3583, -1.4608]],\n","\n","        [[ 0.8397,  0.8029,  1.3402,  ...,  0.5085,  1.0457, -1.3230],\n","         [-0.8283,  0.4975, -1.2396,  ..., -0.2907,  1.2312,  0.6119],\n","         [ 0.6689,  0.8510, -0.4638,  ..., -0.1531,  1.4952, -0.2910],\n","         ...,\n","         [-0.2084,  0.0668, -0.3572,  ...,  0.1785, -0.5267,  0.1211],\n","         [ 1.8586,  1.0106, -2.0471,  ..., -1.5156,  1.4252,  0.3410],\n","         [-0.3483,  1.4775, -0.7931,  ..., -0.9105,  0.2251, -0.0111]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 6.9231e-01,  3.1052e-01,  1.3006e+00,  ...,  9.2103e-02,\n","           1.2207e+00, -1.2594e+00],\n","         [-1.0604e+00,  6.7027e-01, -1.2748e+00,  ...,  7.4046e-01,\n","           2.6159e-01,  1.0544e+00],\n","         [-1.0046e+00,  1.5601e+00,  2.6882e-01,  ..., -3.1203e-01,\n","           5.3766e-01, -1.3888e+00],\n","         ...,\n","         [-4.5416e-01, -6.8192e-01, -7.1323e-01,  ..., -1.7912e-03,\n","           3.4562e-01, -1.4533e+00],\n","         [ 6.2924e-01,  1.7915e+00, -7.4218e-01,  ..., -2.5793e+00,\n","           1.1108e+00,  5.7728e-01],\n","         [ 5.3448e-02,  2.2648e-01,  3.1036e-02,  ...,  1.1732e+00,\n","          -4.0883e-02, -1.1714e+00]],\n","\n","        [[ 7.7598e-01,  4.8752e-01,  1.4623e+00,  ...,  7.0288e-02,\n","           1.1628e+00, -1.0900e+00],\n","         [-7.2245e-01,  6.5731e-01, -9.9265e-01,  ..., -5.0311e-01,\n","           1.3291e+00,  6.6573e-01],\n","         [ 5.3356e-01,  8.9622e-01, -1.6908e-01,  ..., -4.5329e-01,\n","           1.7002e+00, -2.1676e-01],\n","         ...,\n","         [-2.4070e-01,  2.4807e-01, -3.6371e-02,  ..., -1.1488e-01,\n","          -2.7622e-01,  2.0395e-01],\n","         [ 1.7266e+00,  1.1490e+00, -1.5864e+00,  ..., -1.7815e+00,\n","           1.6587e+00,  4.5132e-01],\n","         [-4.2244e-01,  1.5969e+00, -4.2960e-01,  ..., -1.1862e+00,\n","           5.1322e-01,  8.2340e-02]]], grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[ 0.8260,  0.0811,  1.3142,  ..., -0.1757,  1.1370, -1.4941],\n","         [-1.2175,  0.6819, -1.0290,  ...,  0.7689,  0.2835,  1.0876],\n","         [-0.9027,  1.3983,  0.3676,  ..., -0.4453,  0.7100, -1.6140],\n","         ...,\n","         [-0.2438, -0.6807, -0.9654,  ..., -0.1007,  0.5427, -1.2363],\n","         [ 0.5785,  1.6015, -0.7402,  ..., -2.4452,  0.8074,  0.2533],\n","         [-0.0834,  0.0383,  0.3666,  ...,  0.7458,  0.3655, -1.4185]],\n","\n","        [[ 0.9763,  0.2182,  1.4630,  ..., -0.1591,  1.1132, -1.3550],\n","         [-0.4493,  0.6364, -1.0199,  ..., -0.5227,  1.2510,  0.6208],\n","         [ 0.7608,  0.6720, -0.1500,  ..., -0.3732,  1.8061, -0.2244],\n","         ...,\n","         [-0.3540,  0.0563,  0.0083,  ..., -0.1398, -0.2175,  0.1572],\n","         [ 1.7230,  1.1380, -1.6627,  ..., -1.8692,  1.4683,  0.7143],\n","         [-0.3137,  1.5382, -0.2888,  ..., -1.2080,  0.3717, -0.1133]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Shape of Decoder output torch.Size([2, 8, 512])\n","3-th Decoder output is tensor([[[ 0.8260,  0.0811,  1.3142,  ..., -0.1757,  1.1370, -1.4941],\n","         [-1.2175,  0.6819, -1.0290,  ...,  0.7689,  0.2835,  1.0876],\n","         [-0.9027,  1.3983,  0.3676,  ..., -0.4453,  0.7100, -1.6140],\n","         ...,\n","         [-0.2438, -0.6807, -0.9654,  ..., -0.1007,  0.5427, -1.2363],\n","         [ 0.5785,  1.6015, -0.7402,  ..., -2.4452,  0.8074,  0.2533],\n","         [-0.0834,  0.0383,  0.3666,  ...,  0.7458,  0.3655, -1.4185]],\n","\n","        [[ 0.9763,  0.2182,  1.4630,  ..., -0.1591,  1.1132, -1.3550],\n","         [-0.4493,  0.6364, -1.0199,  ..., -0.5227,  1.2510,  0.6208],\n","         [ 0.7608,  0.6720, -0.1500,  ..., -0.3732,  1.8061, -0.2244],\n","         ...,\n","         [-0.3540,  0.0563,  0.0083,  ..., -0.1398, -0.2175,  0.1572],\n","         [ 1.7230,  1.1380, -1.6627,  ..., -1.8692,  1.4683,  0.7143],\n","         [-0.3137,  1.5382, -0.2888,  ..., -1.2080,  0.3717, -0.1133]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[ 0.2109,  0.2690,  1.5092,  ..., -0.1699,  0.0856, -1.1040],\n","         [-1.7150,  0.7602, -1.0327,  ...,  0.3971, -0.5589,  1.3411],\n","         [-1.4014,  1.3071,  0.4061,  ..., -0.6702, -0.0670, -1.2183],\n","         ...,\n","         [-0.7046, -0.5970, -0.9328,  ..., -0.1380,  0.0236, -0.8507],\n","         [ 0.1221,  1.5197, -0.7013,  ..., -2.4696,  0.3673,  0.5616],\n","         [-0.5026,  0.0526,  0.3418,  ...,  0.6511, -0.0691, -1.0834]],\n","\n","        [[ 0.2882,  0.3108,  1.7398,  ..., -0.3602, -0.0186, -1.0348],\n","         [-1.0970,  0.5797, -0.8328,  ..., -0.8626,  0.4174,  0.7523],\n","         [ 0.1688,  0.5684,  0.1043,  ..., -0.6824,  1.0196, -0.0038],\n","         ...,\n","         [-0.7360, -0.0466,  0.1050,  ..., -0.4160, -0.8178,  0.5060],\n","         [ 1.3247,  1.0208, -1.4315,  ..., -2.1266,  0.8810,  0.9762],\n","         [-0.6456,  1.4287, -0.1634,  ..., -1.5265, -0.1741,  0.2281]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[-0.1386,  0.0504,  1.2488,  ..., -0.3355,  0.1118, -0.9876],\n","         [-2.1907,  0.8310, -1.1297,  ...,  0.1664, -0.0099,  1.2861],\n","         [-1.7041,  1.3256,  0.1556,  ..., -0.7745, -0.0830, -1.1976],\n","         ...,\n","         [-1.1201, -0.3007, -1.2939,  ..., -0.4240,  0.1134, -0.6118],\n","         [-0.2036,  1.5197, -0.9312,  ..., -2.6000,  0.6146,  0.9990],\n","         [-0.5812,  0.1507,  0.3531,  ...,  0.4941,  0.0783, -1.1122]],\n","\n","        [[-0.0486,  0.1480,  1.4424,  ..., -0.4385, -0.0648, -0.9258],\n","         [-1.5199,  0.8832, -1.0421,  ..., -0.8216,  0.5877,  0.8788],\n","         [-0.1914,  0.3120, -0.1717,  ..., -0.7805,  1.2735,  0.1143],\n","         ...,\n","         [-1.2564,  0.3481, -0.2715,  ..., -0.6783, -0.4108,  0.5801],\n","         [ 0.7685,  0.9618, -1.5838,  ..., -2.1061,  1.1570,  1.3208],\n","         [-0.5986,  1.5153, -0.2484,  ..., -1.5517, -0.0398,  0.3301]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Shape of Decoder output torch.Size([2, 8, 512])\n","4-th Decoder output is tensor([[[-0.1386,  0.0504,  1.2488,  ..., -0.3355,  0.1118, -0.9876],\n","         [-2.1907,  0.8310, -1.1297,  ...,  0.1664, -0.0099,  1.2861],\n","         [-1.7041,  1.3256,  0.1556,  ..., -0.7745, -0.0830, -1.1976],\n","         ...,\n","         [-1.1201, -0.3007, -1.2939,  ..., -0.4240,  0.1134, -0.6118],\n","         [-0.2036,  1.5197, -0.9312,  ..., -2.6000,  0.6146,  0.9990],\n","         [-0.5812,  0.1507,  0.3531,  ...,  0.4941,  0.0783, -1.1122]],\n","\n","        [[-0.0486,  0.1480,  1.4424,  ..., -0.4385, -0.0648, -0.9258],\n","         [-1.5199,  0.8832, -1.0421,  ..., -0.8216,  0.5877,  0.8788],\n","         [-0.1914,  0.3120, -0.1717,  ..., -0.7805,  1.2735,  0.1143],\n","         ...,\n","         [-1.2564,  0.3481, -0.2715,  ..., -0.6783, -0.4108,  0.5801],\n","         [ 0.7685,  0.9618, -1.5838,  ..., -2.1061,  1.1570,  1.3208],\n","         [-0.5986,  1.5153, -0.2484,  ..., -1.5517, -0.0398,  0.3301]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[-0.3420,  0.1758,  1.4759,  ..., -1.5462, -0.1802, -0.6776],\n","         [-2.1995,  0.9304, -0.8450,  ..., -0.7040, -0.1651,  1.3637],\n","         [-1.6052,  1.3461,  0.5513,  ..., -1.4416, -0.1422, -1.0278],\n","         ...,\n","         [-0.8737, -0.3619, -0.8421,  ..., -0.8918,  0.0839, -0.5002],\n","         [ 0.0289,  1.4811, -0.5277,  ..., -2.9693,  0.6052,  1.0197],\n","         [-0.2515,  0.0970,  0.7509,  ...,  0.0214,  0.1036, -1.0702]],\n","\n","        [[-0.3422,  0.0835,  1.7035,  ..., -1.7263, -0.2095, -0.6563],\n","         [-1.5838,  0.7515, -0.5118,  ..., -1.7301,  0.6276,  0.9509],\n","         [-0.0566,  0.0997,  0.3486,  ..., -1.6540,  1.3239,  0.1690],\n","         ...,\n","         [-1.0394,  0.1194,  0.2312,  ..., -1.3932, -0.2035,  0.5951],\n","         [ 1.0032,  0.6921, -1.0906,  ..., -2.7893,  1.3156,  1.2861],\n","         [-0.2944,  1.2253,  0.2101,  ..., -2.2762,  0.1859,  0.3626]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[-3.1013e-01,  3.6652e-01,  1.4528e+00,  ..., -1.5199e+00,\n","          -2.2470e-01, -5.0119e-01],\n","         [-2.2839e+00,  1.0929e+00, -8.4315e-01,  ..., -6.7760e-01,\n","          -1.2714e-01,  1.5425e+00],\n","         [-1.4533e+00,  1.3759e+00,  6.5135e-01,  ..., -1.4546e+00,\n","          -2.8146e-01, -8.5563e-01],\n","         ...,\n","         [-1.0919e+00, -4.2521e-01, -8.4609e-01,  ..., -8.7447e-01,\n","          -3.8886e-04, -4.0104e-01],\n","         [ 2.6342e-01,  1.4733e+00, -4.9262e-01,  ..., -2.6751e+00,\n","           1.1590e+00,  1.1249e+00],\n","         [-6.1151e-02,  6.8922e-02,  8.6059e-01,  ...,  8.7705e-02,\n","           8.0432e-02, -9.3956e-01]],\n","\n","        [[-3.8416e-01,  2.0149e-01,  1.6193e+00,  ..., -1.6830e+00,\n","          -2.4758e-01, -4.5512e-01],\n","         [-1.7982e+00,  8.5480e-01, -5.6685e-01,  ..., -1.7334e+00,\n","           9.0645e-01,  1.0539e+00],\n","         [-2.1948e-03,  1.9665e-01,  4.9173e-01,  ..., -1.4144e+00,\n","           1.3287e+00,  6.6936e-01],\n","         ...,\n","         [-1.2129e+00,  1.5093e-01,  7.0700e-02,  ..., -1.3093e+00,\n","          -4.1258e-01,  8.6055e-01],\n","         [ 9.2841e-01,  9.5258e-01, -1.0091e+00,  ..., -2.7557e+00,\n","           1.6248e+00,  1.6882e+00],\n","         [-3.4439e-01,  1.1619e+00,  4.3500e-01,  ..., -1.8678e+00,\n","           3.0248e-01,  2.9497e-01]]], grad_fn=<NativeLayerNormBackward0>)\n","Shape of Decoder output torch.Size([2, 8, 512])\n","5-th Decoder output is tensor([[[-3.1013e-01,  3.6652e-01,  1.4528e+00,  ..., -1.5199e+00,\n","          -2.2470e-01, -5.0119e-01],\n","         [-2.2839e+00,  1.0929e+00, -8.4315e-01,  ..., -6.7760e-01,\n","          -1.2714e-01,  1.5425e+00],\n","         [-1.4533e+00,  1.3759e+00,  6.5135e-01,  ..., -1.4546e+00,\n","          -2.8146e-01, -8.5563e-01],\n","         ...,\n","         [-1.0919e+00, -4.2521e-01, -8.4609e-01,  ..., -8.7447e-01,\n","          -3.8886e-04, -4.0104e-01],\n","         [ 2.6342e-01,  1.4733e+00, -4.9262e-01,  ..., -2.6751e+00,\n","           1.1590e+00,  1.1249e+00],\n","         [-6.1151e-02,  6.8922e-02,  8.6059e-01,  ...,  8.7705e-02,\n","           8.0432e-02, -9.3956e-01]],\n","\n","        [[-3.8416e-01,  2.0149e-01,  1.6193e+00,  ..., -1.6830e+00,\n","          -2.4758e-01, -4.5512e-01],\n","         [-1.7982e+00,  8.5480e-01, -5.6685e-01,  ..., -1.7334e+00,\n","           9.0645e-01,  1.0539e+00],\n","         [-2.1948e-03,  1.9665e-01,  4.9173e-01,  ..., -1.4144e+00,\n","           1.3287e+00,  6.6936e-01],\n","         ...,\n","         [-1.2129e+00,  1.5093e-01,  7.0700e-02,  ..., -1.3093e+00,\n","          -4.1258e-01,  8.6055e-01],\n","         [ 9.2841e-01,  9.5258e-01, -1.0091e+00,  ..., -2.7557e+00,\n","           1.6248e+00,  1.6882e+00],\n","         [-3.4439e-01,  1.1619e+00,  4.3500e-01,  ..., -1.8678e+00,\n","           3.0248e-01,  2.9497e-01]]], grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (Before FF)\n","tensor([[[-0.5417,  1.0720,  1.2352,  ..., -1.8062,  0.2993, -0.7462],\n","         [-2.3954,  1.6837, -0.8581,  ..., -0.9748,  0.2368,  1.2170],\n","         [-1.6777,  1.8495,  0.6787,  ..., -1.5712,  0.0233, -1.0690],\n","         ...,\n","         [-1.2462,  0.2215, -0.7417,  ..., -0.9474,  0.2937, -0.6191],\n","         [ 0.0327,  2.0041, -0.4428,  ..., -2.6784,  1.3718,  0.8495],\n","         [-0.2681,  0.6375,  0.8423,  ..., -0.0948,  0.2995, -1.0792]],\n","\n","        [[-0.7939,  0.8857,  1.4981,  ..., -1.9556,  0.2993, -0.8821],\n","         [-2.0918,  1.5535, -0.4814,  ..., -1.7381,  1.4506,  0.5872],\n","         [-0.4852,  0.9444,  0.5638,  ..., -1.3076,  1.7336,  0.0847],\n","         ...,\n","         [-1.6969,  0.9082,  0.2652,  ..., -1.2491, -0.0889,  0.2662],\n","         [ 0.4194,  1.6340, -0.8169,  ..., -2.5881,  1.8966,  1.0178],\n","         [-0.8007,  1.7805,  0.5553,  ..., -1.8053,  0.6145, -0.2658]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Value after normalisation. (After FF)\n","tensor([[[-0.1718,  1.0501,  1.4569,  ..., -1.7888,  0.3104, -0.9164],\n","         [-2.2915,  1.4120, -0.4412,  ..., -1.3095,  0.3742,  0.9400],\n","         [-1.6086,  1.8014,  0.8363,  ..., -1.7546, -0.2352, -1.2492],\n","         ...,\n","         [-0.9237,  0.2479, -0.5496,  ..., -1.1265,  0.2650, -0.7109],\n","         [ 0.0366,  1.9573, -0.3776,  ..., -2.5796,  1.0905,  0.9300],\n","         [-0.1898,  0.3875,  0.7625,  ..., -0.2581,  0.1188, -1.3142]],\n","\n","        [[-0.4459,  0.8879,  1.7120,  ..., -1.8844,  0.3622, -1.1822],\n","         [-1.8518,  1.3523,  0.0978,  ..., -1.6416,  1.3796,  0.1667],\n","         [-0.4128,  1.1183,  1.0144,  ..., -1.2694,  1.5953, -0.2979],\n","         ...,\n","         [-1.4869,  0.6427,  0.3670,  ..., -1.4565,  0.0750, -0.0634],\n","         [ 0.5812,  1.6492, -0.3507,  ..., -2.2729,  1.9730,  0.8866],\n","         [-0.6720,  1.4657,  0.6144,  ..., -2.0061,  0.3582, -0.2906]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","Shape of Decoder output torch.Size([2, 8, 512])\n","6-th Decoder output is tensor([[[-0.1718,  1.0501,  1.4569,  ..., -1.7888,  0.3104, -0.9164],\n","         [-2.2915,  1.4120, -0.4412,  ..., -1.3095,  0.3742,  0.9400],\n","         [-1.6086,  1.8014,  0.8363,  ..., -1.7546, -0.2352, -1.2492],\n","         ...,\n","         [-0.9237,  0.2479, -0.5496,  ..., -1.1265,  0.2650, -0.7109],\n","         [ 0.0366,  1.9573, -0.3776,  ..., -2.5796,  1.0905,  0.9300],\n","         [-0.1898,  0.3875,  0.7625,  ..., -0.2581,  0.1188, -1.3142]],\n","\n","        [[-0.4459,  0.8879,  1.7120,  ..., -1.8844,  0.3622, -1.1822],\n","         [-1.8518,  1.3523,  0.0978,  ..., -1.6416,  1.3796,  0.1667],\n","         [-0.4128,  1.1183,  1.0144,  ..., -1.2694,  1.5953, -0.2979],\n","         ...,\n","         [-1.4869,  0.6427,  0.3670,  ..., -1.4565,  0.0750, -0.0634],\n","         [ 0.5812,  1.6492, -0.3507,  ..., -2.2729,  1.9730,  0.8866],\n","         [-0.6720,  1.4657,  0.6144,  ..., -2.0061,  0.3582, -0.2906]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","\n","<Output of decoder after applying Linear layer>\n","\n","Decoder out.shape torch.Size([2, 8, 10])\n","Decoder out tensor([[[-0.0863,  0.7126, -0.3455, -0.7906,  0.2029,  0.8832,  0.2898,\n","           0.2658, -0.1357,  1.2056],\n","         [ 0.3110,  0.1301,  0.1558, -0.2663, -0.8178,  0.5528, -0.8355,\n","           1.0563, -0.2975,  1.4698],\n","         [ 0.2654,  0.4138, -0.4375, -0.1779, -0.6041,  0.9342, -0.3110,\n","           0.6526,  0.1353,  0.9104],\n","         [ 0.1465,  0.5612, -0.6894, -0.4895,  0.3821, -0.2119, -0.4163,\n","           1.1556,  0.1773,  0.9684],\n","         [-0.3522,  0.2117, -0.1137,  0.5105, -0.6108,  0.5489,  0.0688,\n","           0.3786, -1.0342,  1.0280],\n","         [ 0.0384, -0.2730, -0.3231,  0.0633, -0.1433,  0.3109, -1.1827,\n","          -0.2840,  0.0941,  0.3892],\n","         [ 0.1314,  1.1707,  0.3272, -0.1699, -0.9392,  0.3116,  1.1061,\n","           0.4631, -0.1495,  0.4541],\n","         [-0.2222, -0.8293, -0.0591, -0.1443,  0.3391,  0.7729, -0.8235,\n","          -0.3878, -0.5548,  0.9567]],\n","\n","        [[-0.1898,  0.7883, -0.2999, -0.7471,  0.2848,  0.8343,  0.3520,\n","           0.3904, -0.2622,  1.2070],\n","         [-0.5071,  0.6522,  0.0288, -0.2889, -0.2802,  0.6752, -0.0210,\n","           1.0104, -0.6807,  1.2016],\n","         [ 0.5980,  0.5850,  0.2137, -0.4312, -0.2118,  1.3304,  0.1748,\n","           0.3698,  0.4238,  0.5439],\n","         [ 0.3777,  1.2124,  0.3369, -0.4848,  0.0579,  0.1563,  0.4783,\n","           0.8559,  0.1001,  0.2493],\n","         [ 0.3110,  0.6292,  0.0348,  0.4736, -0.9419,  0.5024, -0.0669,\n","           0.9934, -0.5985,  0.8002],\n","         [ 0.2993, -0.9183,  0.0766,  0.2519, -0.4491,  0.3548, -1.3565,\n","           0.5569, -0.3130,  0.3941],\n","         [ 0.1199,  0.6960,  0.6170, -0.3177, -0.4938,  0.6515,  0.4524,\n","           0.5291,  0.2113,  0.5850],\n","         [ 0.0784,  0.5075,  0.6134, -0.1913,  0.3624,  0.5564,  0.5680,\n","          -0.0298, -0.7722,  0.4062]]], grad_fn=<AddBackward0>)\n","\n","<Output of decoder after applying Linear layer>\n","\n","torch.Size([2, 8, 10])\n","tensor([[[-0.0863,  0.7126, -0.3455, -0.7906,  0.2029,  0.8832,  0.2898,\n","           0.2658, -0.1357,  1.2056],\n","         [ 0.3110,  0.1301,  0.1558, -0.2663, -0.8178,  0.5528, -0.8355,\n","           1.0563, -0.2975,  1.4698],\n","         [ 0.2654,  0.4138, -0.4375, -0.1779, -0.6041,  0.9342, -0.3110,\n","           0.6526,  0.1353,  0.9104],\n","         [ 0.1465,  0.5612, -0.6894, -0.4895,  0.3821, -0.2119, -0.4163,\n","           1.1556,  0.1773,  0.9684],\n","         [-0.3522,  0.2117, -0.1137,  0.5105, -0.6108,  0.5489,  0.0688,\n","           0.3786, -1.0342,  1.0280],\n","         [ 0.0384, -0.2730, -0.3231,  0.0633, -0.1433,  0.3109, -1.1827,\n","          -0.2840,  0.0941,  0.3892],\n","         [ 0.1314,  1.1707,  0.3272, -0.1699, -0.9392,  0.3116,  1.1061,\n","           0.4631, -0.1495,  0.4541],\n","         [-0.2222, -0.8293, -0.0591, -0.1443,  0.3391,  0.7729, -0.8235,\n","          -0.3878, -0.5548,  0.9567]],\n","\n","        [[-0.1898,  0.7883, -0.2999, -0.7471,  0.2848,  0.8343,  0.3520,\n","           0.3904, -0.2622,  1.2070],\n","         [-0.5071,  0.6522,  0.0288, -0.2889, -0.2802,  0.6752, -0.0210,\n","           1.0104, -0.6807,  1.2016],\n","         [ 0.5980,  0.5850,  0.2137, -0.4312, -0.2118,  1.3304,  0.1748,\n","           0.3698,  0.4238,  0.5439],\n","         [ 0.3777,  1.2124,  0.3369, -0.4848,  0.0579,  0.1563,  0.4783,\n","           0.8559,  0.1001,  0.2493],\n","         [ 0.3110,  0.6292,  0.0348,  0.4736, -0.9419,  0.5024, -0.0669,\n","           0.9934, -0.5985,  0.8002],\n","         [ 0.2993, -0.9183,  0.0766,  0.2519, -0.4491,  0.3548, -1.3565,\n","           0.5569, -0.3130,  0.3941],\n","         [ 0.1199,  0.6960,  0.6170, -0.3177, -0.4938,  0.6515,  0.4524,\n","           0.5291,  0.2113,  0.5850],\n","         [ 0.0784,  0.5075,  0.6134, -0.1913,  0.3624,  0.5564,  0.5680,\n","          -0.0298, -0.7722,  0.4062]]], grad_fn=<AddBackward0>)\n","=============================== main done ===============================\n"]}]},{"cell_type":"code","source":["count_parameters(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTAznQXIZn3T","executionInfo":{"status":"ok","timestamp":1645517088819,"user_tz":-540,"elapsed":12,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"c25c1fe5-235d-4da4-ffac-f9bc7dc0529e"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------+------------+\n","|                           Modules                           | Parameters |\n","+-------------------------------------------------------------+------------+\n","|                encoder.word_embedding.weight                |    5120    |\n","|              encoder.position_embedding.weight              |   51200    |\n","|           encoder.layers.0.attention.values.weight          |    4096    |\n","|            encoder.layers.0.attention.keys.weight           |    4096    |\n","|          encoder.layers.0.attention.queries.weight          |    4096    |\n","|           encoder.layers.0.attention.fc_out.weight          |   262144   |\n","|            encoder.layers.0.attention.fc_out.bias           |    512     |\n","|                encoder.layers.0.norm1.weight                |    512     |\n","|                 encoder.layers.0.norm1.bias                 |    512     |\n","|                encoder.layers.0.norm2.weight                |    512     |\n","|                 encoder.layers.0.norm2.bias                 |    512     |\n","|            encoder.layers.0.feed_forward.0.weight           |  1048576   |\n","|             encoder.layers.0.feed_forward.0.bias            |    2048    |\n","|            encoder.layers.0.feed_forward.2.weight           |  1048576   |\n","|             encoder.layers.0.feed_forward.2.bias            |    512     |\n","|           encoder.layers.1.attention.values.weight          |    4096    |\n","|            encoder.layers.1.attention.keys.weight           |    4096    |\n","|          encoder.layers.1.attention.queries.weight          |    4096    |\n","|           encoder.layers.1.attention.fc_out.weight          |   262144   |\n","|            encoder.layers.1.attention.fc_out.bias           |    512     |\n","|                encoder.layers.1.norm1.weight                |    512     |\n","|                 encoder.layers.1.norm1.bias                 |    512     |\n","|                encoder.layers.1.norm2.weight                |    512     |\n","|                 encoder.layers.1.norm2.bias                 |    512     |\n","|            encoder.layers.1.feed_forward.0.weight           |  1048576   |\n","|             encoder.layers.1.feed_forward.0.bias            |    2048    |\n","|            encoder.layers.1.feed_forward.2.weight           |  1048576   |\n","|             encoder.layers.1.feed_forward.2.bias            |    512     |\n","|           encoder.layers.2.attention.values.weight          |    4096    |\n","|            encoder.layers.2.attention.keys.weight           |    4096    |\n","|          encoder.layers.2.attention.queries.weight          |    4096    |\n","|           encoder.layers.2.attention.fc_out.weight          |   262144   |\n","|            encoder.layers.2.attention.fc_out.bias           |    512     |\n","|                encoder.layers.2.norm1.weight                |    512     |\n","|                 encoder.layers.2.norm1.bias                 |    512     |\n","|                encoder.layers.2.norm2.weight                |    512     |\n","|                 encoder.layers.2.norm2.bias                 |    512     |\n","|            encoder.layers.2.feed_forward.0.weight           |  1048576   |\n","|             encoder.layers.2.feed_forward.0.bias            |    2048    |\n","|            encoder.layers.2.feed_forward.2.weight           |  1048576   |\n","|             encoder.layers.2.feed_forward.2.bias            |    512     |\n","|           encoder.layers.3.attention.values.weight          |    4096    |\n","|            encoder.layers.3.attention.keys.weight           |    4096    |\n","|          encoder.layers.3.attention.queries.weight          |    4096    |\n","|           encoder.layers.3.attention.fc_out.weight          |   262144   |\n","|            encoder.layers.3.attention.fc_out.bias           |    512     |\n","|                encoder.layers.3.norm1.weight                |    512     |\n","|                 encoder.layers.3.norm1.bias                 |    512     |\n","|                encoder.layers.3.norm2.weight                |    512     |\n","|                 encoder.layers.3.norm2.bias                 |    512     |\n","|            encoder.layers.3.feed_forward.0.weight           |  1048576   |\n","|             encoder.layers.3.feed_forward.0.bias            |    2048    |\n","|            encoder.layers.3.feed_forward.2.weight           |  1048576   |\n","|             encoder.layers.3.feed_forward.2.bias            |    512     |\n","|           encoder.layers.4.attention.values.weight          |    4096    |\n","|            encoder.layers.4.attention.keys.weight           |    4096    |\n","|          encoder.layers.4.attention.queries.weight          |    4096    |\n","|           encoder.layers.4.attention.fc_out.weight          |   262144   |\n","|            encoder.layers.4.attention.fc_out.bias           |    512     |\n","|                encoder.layers.4.norm1.weight                |    512     |\n","|                 encoder.layers.4.norm1.bias                 |    512     |\n","|                encoder.layers.4.norm2.weight                |    512     |\n","|                 encoder.layers.4.norm2.bias                 |    512     |\n","|            encoder.layers.4.feed_forward.0.weight           |  1048576   |\n","|             encoder.layers.4.feed_forward.0.bias            |    2048    |\n","|            encoder.layers.4.feed_forward.2.weight           |  1048576   |\n","|             encoder.layers.4.feed_forward.2.bias            |    512     |\n","|           encoder.layers.5.attention.values.weight          |    4096    |\n","|            encoder.layers.5.attention.keys.weight           |    4096    |\n","|          encoder.layers.5.attention.queries.weight          |    4096    |\n","|           encoder.layers.5.attention.fc_out.weight          |   262144   |\n","|            encoder.layers.5.attention.fc_out.bias           |    512     |\n","|                encoder.layers.5.norm1.weight                |    512     |\n","|                 encoder.layers.5.norm1.bias                 |    512     |\n","|                encoder.layers.5.norm2.weight                |    512     |\n","|                 encoder.layers.5.norm2.bias                 |    512     |\n","|            encoder.layers.5.feed_forward.0.weight           |  1048576   |\n","|             encoder.layers.5.feed_forward.0.bias            |    2048    |\n","|            encoder.layers.5.feed_forward.2.weight           |  1048576   |\n","|             encoder.layers.5.feed_forward.2.bias            |    512     |\n","|                decoder.word_embedding.weight                |    5120    |\n","|              decoder.position_embedding.weight              |   51200    |\n","|                 decoder.layers.0.norm.weight                |    512     |\n","|                  decoder.layers.0.norm.bias                 |    512     |\n","|           decoder.layers.0.attention.values.weight          |    4096    |\n","|            decoder.layers.0.attention.keys.weight           |    4096    |\n","|          decoder.layers.0.attention.queries.weight          |    4096    |\n","|           decoder.layers.0.attention.fc_out.weight          |   262144   |\n","|            decoder.layers.0.attention.fc_out.bias           |    512     |\n","|  decoder.layers.0.transformer_block.attention.values.weight |    4096    |\n","|   decoder.layers.0.transformer_block.attention.keys.weight  |    4096    |\n","| decoder.layers.0.transformer_block.attention.queries.weight |    4096    |\n","|  decoder.layers.0.transformer_block.attention.fc_out.weight |   262144   |\n","|   decoder.layers.0.transformer_block.attention.fc_out.bias  |    512     |\n","|       decoder.layers.0.transformer_block.norm1.weight       |    512     |\n","|        decoder.layers.0.transformer_block.norm1.bias        |    512     |\n","|       decoder.layers.0.transformer_block.norm2.weight       |    512     |\n","|        decoder.layers.0.transformer_block.norm2.bias        |    512     |\n","|   decoder.layers.0.transformer_block.feed_forward.0.weight  |  1048576   |\n","|    decoder.layers.0.transformer_block.feed_forward.0.bias   |    2048    |\n","|   decoder.layers.0.transformer_block.feed_forward.2.weight  |  1048576   |\n","|    decoder.layers.0.transformer_block.feed_forward.2.bias   |    512     |\n","|                 decoder.layers.1.norm.weight                |    512     |\n","|                  decoder.layers.1.norm.bias                 |    512     |\n","|           decoder.layers.1.attention.values.weight          |    4096    |\n","|            decoder.layers.1.attention.keys.weight           |    4096    |\n","|          decoder.layers.1.attention.queries.weight          |    4096    |\n","|           decoder.layers.1.attention.fc_out.weight          |   262144   |\n","|            decoder.layers.1.attention.fc_out.bias           |    512     |\n","|  decoder.layers.1.transformer_block.attention.values.weight |    4096    |\n","|   decoder.layers.1.transformer_block.attention.keys.weight  |    4096    |\n","| decoder.layers.1.transformer_block.attention.queries.weight |    4096    |\n","|  decoder.layers.1.transformer_block.attention.fc_out.weight |   262144   |\n","|   decoder.layers.1.transformer_block.attention.fc_out.bias  |    512     |\n","|       decoder.layers.1.transformer_block.norm1.weight       |    512     |\n","|        decoder.layers.1.transformer_block.norm1.bias        |    512     |\n","|       decoder.layers.1.transformer_block.norm2.weight       |    512     |\n","|        decoder.layers.1.transformer_block.norm2.bias        |    512     |\n","|   decoder.layers.1.transformer_block.feed_forward.0.weight  |  1048576   |\n","|    decoder.layers.1.transformer_block.feed_forward.0.bias   |    2048    |\n","|   decoder.layers.1.transformer_block.feed_forward.2.weight  |  1048576   |\n","|    decoder.layers.1.transformer_block.feed_forward.2.bias   |    512     |\n","|                 decoder.layers.2.norm.weight                |    512     |\n","|                  decoder.layers.2.norm.bias                 |    512     |\n","|           decoder.layers.2.attention.values.weight          |    4096    |\n","|            decoder.layers.2.attention.keys.weight           |    4096    |\n","|          decoder.layers.2.attention.queries.weight          |    4096    |\n","|           decoder.layers.2.attention.fc_out.weight          |   262144   |\n","|            decoder.layers.2.attention.fc_out.bias           |    512     |\n","|  decoder.layers.2.transformer_block.attention.values.weight |    4096    |\n","|   decoder.layers.2.transformer_block.attention.keys.weight  |    4096    |\n","| decoder.layers.2.transformer_block.attention.queries.weight |    4096    |\n","|  decoder.layers.2.transformer_block.attention.fc_out.weight |   262144   |\n","|   decoder.layers.2.transformer_block.attention.fc_out.bias  |    512     |\n","|       decoder.layers.2.transformer_block.norm1.weight       |    512     |\n","|        decoder.layers.2.transformer_block.norm1.bias        |    512     |\n","|       decoder.layers.2.transformer_block.norm2.weight       |    512     |\n","|        decoder.layers.2.transformer_block.norm2.bias        |    512     |\n","|   decoder.layers.2.transformer_block.feed_forward.0.weight  |  1048576   |\n","|    decoder.layers.2.transformer_block.feed_forward.0.bias   |    2048    |\n","|   decoder.layers.2.transformer_block.feed_forward.2.weight  |  1048576   |\n","|    decoder.layers.2.transformer_block.feed_forward.2.bias   |    512     |\n","|                 decoder.layers.3.norm.weight                |    512     |\n","|                  decoder.layers.3.norm.bias                 |    512     |\n","|           decoder.layers.3.attention.values.weight          |    4096    |\n","|            decoder.layers.3.attention.keys.weight           |    4096    |\n","|          decoder.layers.3.attention.queries.weight          |    4096    |\n","|           decoder.layers.3.attention.fc_out.weight          |   262144   |\n","|            decoder.layers.3.attention.fc_out.bias           |    512     |\n","|  decoder.layers.3.transformer_block.attention.values.weight |    4096    |\n","|   decoder.layers.3.transformer_block.attention.keys.weight  |    4096    |\n","| decoder.layers.3.transformer_block.attention.queries.weight |    4096    |\n","|  decoder.layers.3.transformer_block.attention.fc_out.weight |   262144   |\n","|   decoder.layers.3.transformer_block.attention.fc_out.bias  |    512     |\n","|       decoder.layers.3.transformer_block.norm1.weight       |    512     |\n","|        decoder.layers.3.transformer_block.norm1.bias        |    512     |\n","|       decoder.layers.3.transformer_block.norm2.weight       |    512     |\n","|        decoder.layers.3.transformer_block.norm2.bias        |    512     |\n","|   decoder.layers.3.transformer_block.feed_forward.0.weight  |  1048576   |\n","|    decoder.layers.3.transformer_block.feed_forward.0.bias   |    2048    |\n","|   decoder.layers.3.transformer_block.feed_forward.2.weight  |  1048576   |\n","|    decoder.layers.3.transformer_block.feed_forward.2.bias   |    512     |\n","|                 decoder.layers.4.norm.weight                |    512     |\n","|                  decoder.layers.4.norm.bias                 |    512     |\n","|           decoder.layers.4.attention.values.weight          |    4096    |\n","|            decoder.layers.4.attention.keys.weight           |    4096    |\n","|          decoder.layers.4.attention.queries.weight          |    4096    |\n","|           decoder.layers.4.attention.fc_out.weight          |   262144   |\n","|            decoder.layers.4.attention.fc_out.bias           |    512     |\n","|  decoder.layers.4.transformer_block.attention.values.weight |    4096    |\n","|   decoder.layers.4.transformer_block.attention.keys.weight  |    4096    |\n","| decoder.layers.4.transformer_block.attention.queries.weight |    4096    |\n","|  decoder.layers.4.transformer_block.attention.fc_out.weight |   262144   |\n","|   decoder.layers.4.transformer_block.attention.fc_out.bias  |    512     |\n","|       decoder.layers.4.transformer_block.norm1.weight       |    512     |\n","|        decoder.layers.4.transformer_block.norm1.bias        |    512     |\n","|       decoder.layers.4.transformer_block.norm2.weight       |    512     |\n","|        decoder.layers.4.transformer_block.norm2.bias        |    512     |\n","|   decoder.layers.4.transformer_block.feed_forward.0.weight  |  1048576   |\n","|    decoder.layers.4.transformer_block.feed_forward.0.bias   |    2048    |\n","|   decoder.layers.4.transformer_block.feed_forward.2.weight  |  1048576   |\n","|    decoder.layers.4.transformer_block.feed_forward.2.bias   |    512     |\n","|                 decoder.layers.5.norm.weight                |    512     |\n","|                  decoder.layers.5.norm.bias                 |    512     |\n","|           decoder.layers.5.attention.values.weight          |    4096    |\n","|            decoder.layers.5.attention.keys.weight           |    4096    |\n","|          decoder.layers.5.attention.queries.weight          |    4096    |\n","|           decoder.layers.5.attention.fc_out.weight          |   262144   |\n","|            decoder.layers.5.attention.fc_out.bias           |    512     |\n","|  decoder.layers.5.transformer_block.attention.values.weight |    4096    |\n","|   decoder.layers.5.transformer_block.attention.keys.weight  |    4096    |\n","| decoder.layers.5.transformer_block.attention.queries.weight |    4096    |\n","|  decoder.layers.5.transformer_block.attention.fc_out.weight |   262144   |\n","|   decoder.layers.5.transformer_block.attention.fc_out.bias  |    512     |\n","|       decoder.layers.5.transformer_block.norm1.weight       |    512     |\n","|        decoder.layers.5.transformer_block.norm1.bias        |    512     |\n","|       decoder.layers.5.transformer_block.norm2.weight       |    512     |\n","|        decoder.layers.5.transformer_block.norm2.bias        |    512     |\n","|   decoder.layers.5.transformer_block.feed_forward.0.weight  |  1048576   |\n","|    decoder.layers.5.transformer_block.feed_forward.0.bias   |    2048    |\n","|   decoder.layers.5.transformer_block.feed_forward.2.weight  |  1048576   |\n","|    decoder.layers.5.transformer_block.feed_forward.2.bias   |    512     |\n","|                    decoder.fc_out.weight                    |    5120    |\n","|                     decoder.fc_out.bias                     |     10     |\n","+-------------------------------------------------------------+------------+\n","Total Trainable Params: 30294026\n"]},{"output_type":"execute_result","data":{"text/plain":["30294026"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":[""],"metadata":{"id":"d1LjvhyzXyVm","executionInfo":{"status":"ok","timestamp":1645517089412,"user_tz":-540,"elapsed":3,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":42,"outputs":[]}]}