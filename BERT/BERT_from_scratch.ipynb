{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_from_scratch.ipynb","provenance":[],"authorship_tag":"ABX9TyO8rmrRf5hDFSoQwr8rM7kK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install d2l"],"metadata":{"id":"YOv8FxzCNyNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from d2l import torch as d2l"],"metadata":{"id":"O7etxbpQOIyI","executionInfo":{"status":"ok","timestamp":1644214220449,"user_tz":-540,"elapsed":485,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJgpK3vZWXgD","executionInfo":{"status":"ok","timestamp":1644214220969,"user_tz":-540,"elapsed":6,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"64fa81fe-4905-407f-f700-0796f1b3e9d7"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f76c606c250>"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["def get_tokens_and_segments(tokens_a, tokens_b=None):\n","    \"\"\"Get tokens of the BERT input sequence and their segment IDs.\"\"\"\n","    tokens = ['<cls>'] + tokens_a + ['<sep>']\n","    # 0 and 1 are marking segment A and B, respectively\n","    segments = [0] * (len(tokens_a) + 2)\n","    if tokens_b is not None:\n","        tokens += tokens_b + ['<sep>']\n","        segments += [1] * (len(tokens_b) + 1)\n","    return tokens, segments"],"metadata":{"id":"iz4dv2MLQos0","executionInfo":{"status":"ok","timestamp":1644214220969,"user_tz":-540,"elapsed":2,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["class BERTEncoder(nn.Module):\n","    \"\"\"BERT encoder.\"\"\"\n","    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n","                 ffn_num_hiddens, num_heads, num_layers, dropout,\n","                 max_len=1000, key_size=768, query_size=768, value_size=768,\n","                 **kwargs):\n","        super(BERTEncoder, self).__init__(**kwargs)\n","        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n","        self.segment_embedding = nn.Embedding(2, num_hiddens)\n","        self.blks = nn.Sequential()\n","        for i in range(num_layers):\n","            self.blks.add_module(f\"{i}\", d2l.EncoderBlock(\n","                key_size, query_size, value_size, num_hiddens, norm_shape,\n","                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))\n","        # In BERT, positional embeddings are learnable, thus we create a\n","        # parameter of positional embeddings that are long enough\n","        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n","                                                      num_hiddens))\n","\n","    def forward(self, tokens, segments, valid_lens):\n","        # Shape of `X` remains unchanged in the following code snippet:\n","        # (batch size, max sequence length, `num_hiddens`)\n","        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n","        X = X + self.pos_embedding.data[:, :X.shape[1], :]\n","        for blk in self.blks:\n","            X = blk(X, valid_lens)\n","        return X"],"metadata":{"id":"HGXIqTLeQouv","executionInfo":{"status":"ok","timestamp":1644214220969,"user_tz":-540,"elapsed":1,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 8   # num_hiddens == 단어의 벡터 사이즈 (ex. hello를 768차원의 vector로 변환), \n","                                                                            # num_heads == number of attention heads\n","\n","norm_shape, ffn_num_input, num_layers, dropout = [768], 768, 2, 0.2         # num_layers == encoder을 몇층으로 쌓을 것인지. 현재는 2개의 encoder층을 사용.\n","encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input,\n","                      ffn_num_hiddens, num_heads, num_layers, dropout)"],"metadata":{"id":"X84ZZIkTQows","executionInfo":{"status":"ok","timestamp":1644214221334,"user_tz":-540,"elapsed":1,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["tokens = torch.randint(0, vocab_size, (2, 8))\n","segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n","encoded_X = encoder.forward(tokens, segments, None)\n","encoded_X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwdAg_DCQoym","executionInfo":{"status":"ok","timestamp":1644214221658,"user_tz":-540,"elapsed":4,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"153c8948-8381-4076-fcc3-a4e62c81c673"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 8, 768])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["print(\"<tokens>\\n\", tokens)\n","print(\"<segments>\\n\", segments)\n","print(\"<encoded_X>\\n\", encoded_X)\n","print(\"<encoded_X shape>\\n\", encoded_X.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0GbmFVEQo0L","executionInfo":{"status":"ok","timestamp":1644214222021,"user_tz":-540,"elapsed":3,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"bb743c75-aff8-4fff-abf1-6b635b632a42"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["<tokens>\n"," tensor([[4858,  917, 3476, 2037, 7606,  861, 7568, 7817],\n","        [2150, 6105, 8858, 3022, 3627, 7127, 5883, 3532]])\n","<segments>\n"," tensor([[0, 0, 0, 0, 1, 1, 1, 1],\n","        [0, 0, 0, 1, 1, 1, 1, 1]])\n","<encoded_X>\n"," tensor([[[-0.5286,  0.3016, -0.4203,  ...,  0.0112, -0.1836, -1.3297],\n","         [ 0.1406,  0.7733, -0.5899,  ..., -0.7012, -0.0203, -0.6223],\n","         [-0.2488,  0.3336, -0.5518,  ...,  0.8301, -0.7823, -0.5448],\n","         ...,\n","         [ 0.5903, -0.8835, -0.5691,  ...,  0.1666,  1.3983,  0.3773],\n","         [ 0.2549, -1.7121, -0.1971,  ...,  1.6140,  1.9709,  1.2390],\n","         [ 0.0525, -0.9108, -0.4603,  ...,  0.0295, -1.5802,  0.6551]],\n","\n","        [[-0.4768,  1.0896, -0.9751,  ..., -0.4609,  0.8449, -0.6628],\n","         [-0.4958, -0.1381, -0.9755,  ..., -0.0809, -1.8703, -0.2887],\n","         [-0.6969,  0.3877, -0.1077,  ..., -0.2207, -0.7544, -0.6168],\n","         ...,\n","         [-0.5083,  0.0279, -0.0965,  ...,  0.1518,  0.0735,  0.9332],\n","         [ 0.3751, -0.9816, -0.2527,  ...,  1.0946,  2.2712, -0.2490],\n","         [-0.3272, -1.4356,  0.2839,  ..., -0.2339,  1.1465, -0.3653]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","<encoded_X shape>\n"," torch.Size([2, 8, 768])\n"]}]},{"cell_type":"code","source":["# Masked Language Modelling\n","class MaskLM(nn.Module):\n","    \"\"\"The masked language model task of BERT.\"\"\"\n","    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):\n","        super(MaskLM, self).__init__(**kwargs)\n","        self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens),\n","                                 nn.ReLU(),\n","                                 nn.LayerNorm(num_hiddens),\n","                                 nn.Linear(num_hiddens, vocab_size))\n","\n","    def forward(self, X, pred_positions):\n","        num_pred_positions = pred_positions.shape[1]\n","        pred_positions = pred_positions.reshape(-1)\n","        batch_size = X.shape[0]\n","        batch_idx = torch.arange(0, batch_size)\n","        # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then\n","        # `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`\n","        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n","        masked_X = X[batch_idx, pred_positions]\n","        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n","        mlm_Y_hat = self.mlp(masked_X)\n","        return mlm_Y_hat"],"metadata":{"id":"F-6CMOQmQo2H","executionInfo":{"status":"ok","timestamp":1644214222021,"user_tz":-540,"elapsed":1,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["mlm = MaskLM(vocab_size, num_hiddens)   # vocab_size == 10000, num_hiddens == 768\n","mlm_positions = torch.tensor([[1, 5, 7], [6, 1, 5]]) # mlm_positions == 가릴 위치를 선택\n","mlm_Y_hat = mlm.forward(encoded_X, mlm_positions)\n","mlm_Y_hat.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5sFu6kNQo4B","executionInfo":{"status":"ok","timestamp":1644214223159,"user_tz":-540,"elapsed":409,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"1bb021bb-4c49-4e1e-ed7e-3d3b12080e5f"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3, 10000])"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["We define mlm_positions as the 3 indices to predict in either BERT input sequence of encoded_X. The forward inference of mlm returns prediction results mlm_Y_hat at all the masked positions mlm_positions of encoded_X. For each prediction, the size of the result is equal to the vocabulary size."],"metadata":{"id":"Mg1dfFvUtd4Y"}},{"cell_type":"code","source":["print(\"<encoded_X>\\n\", encoded_X)\n","print(\"<encoded_X shape>\\n\", encoded_X.shape)\n","print(\"---------------------------------------\")\n","print(\"<mlm_position>\\n\", mlm_positions)\n","print(\"<mlm_positions shape>\\n\", mlm_positions.shape)\n","print(\"---------------------------------------\")\n","print(\"<mlm_Y_hat>\\n\", mlm_Y_hat)\n","print(\"<mlm_Y_hat shape>\\n\", mlm_Y_hat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_L5nlodlmby","executionInfo":{"status":"ok","timestamp":1644214224444,"user_tz":-540,"elapsed":2,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"96646911-5c64-4000-ae87-fccbcbc92f9a"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["<encoded_X>\n"," tensor([[[-0.5286,  0.3016, -0.4203,  ...,  0.0112, -0.1836, -1.3297],\n","         [ 0.1406,  0.7733, -0.5899,  ..., -0.7012, -0.0203, -0.6223],\n","         [-0.2488,  0.3336, -0.5518,  ...,  0.8301, -0.7823, -0.5448],\n","         ...,\n","         [ 0.5903, -0.8835, -0.5691,  ...,  0.1666,  1.3983,  0.3773],\n","         [ 0.2549, -1.7121, -0.1971,  ...,  1.6140,  1.9709,  1.2390],\n","         [ 0.0525, -0.9108, -0.4603,  ...,  0.0295, -1.5802,  0.6551]],\n","\n","        [[-0.4768,  1.0896, -0.9751,  ..., -0.4609,  0.8449, -0.6628],\n","         [-0.4958, -0.1381, -0.9755,  ..., -0.0809, -1.8703, -0.2887],\n","         [-0.6969,  0.3877, -0.1077,  ..., -0.2207, -0.7544, -0.6168],\n","         ...,\n","         [-0.5083,  0.0279, -0.0965,  ...,  0.1518,  0.0735,  0.9332],\n","         [ 0.3751, -0.9816, -0.2527,  ...,  1.0946,  2.2712, -0.2490],\n","         [-0.3272, -1.4356,  0.2839,  ..., -0.2339,  1.1465, -0.3653]]],\n","       grad_fn=<NativeLayerNormBackward0>)\n","<encoded_X shape>\n"," torch.Size([2, 8, 768])\n","---------------------------------------\n","<mlm_position>\n"," tensor([[1, 5, 7],\n","        [6, 1, 5]])\n","<mlm_positions shape>\n"," torch.Size([2, 3])\n","---------------------------------------\n","<mlm_Y_hat>\n"," tensor([[[-0.4304,  0.0563,  0.1566,  ...,  0.3092, -0.6604,  0.2908],\n","         [-0.7362, -0.3627, -0.5952,  ...,  0.1633,  0.0603,  0.2548],\n","         [-0.9460, -0.3693,  0.1905,  ...,  0.3316,  0.3007, -0.4621]],\n","\n","        [[-0.5851, -0.3564, -0.7247,  ...,  0.6641, -0.1380,  0.2987],\n","         [-0.0319, -0.0562,  0.1862,  ...,  0.2184, -0.1564,  0.5300],\n","         [-0.3912,  0.1816, -0.0865,  ..., -0.3465,  0.6715,  1.2724]]],\n","       grad_fn=<AddBackward0>)\n","<mlm_Y_hat shape>\n"," torch.Size([2, 3, 10000])\n"]}]},{"cell_type":"code","source":["mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])\n","loss = nn.CrossEntropyLoss(reduction='none')\n","mlm_loss = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))\n","mlm_loss.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SX-rlc9qlmd9","executionInfo":{"status":"ok","timestamp":1644214228037,"user_tz":-540,"elapsed":326,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"ed529224-eee4-4ef6-d92b-8e05c0ca1ee2"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6])"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["print(\"mlm_Y_hat\\n\",mlm_Y_hat)\n","print(\"mlm_Y_hat shape\\n\",mlm_Y_hat.shape)\n","print(\"---------------------------------------\")\n","print(\"mlm_Y\\n\", mlm_Y)\n","print(\"mlm_Y shape\\n\", mlm_Y.shape)\n","print(\"---------------------------------------\")\n","print(\"<mlm_Y_hat.reshape(-1, vocab_size).shape>\\n\", mlm_Y_hat.reshape(-1, vocab_size).shape)\n","print(\"<mlm_Y.reshape(-1).shape>\\n\", mlm_Y.reshape(-1).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_DHru8AQo6E","executionInfo":{"status":"ok","timestamp":1644214228448,"user_tz":-540,"elapsed":6,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"0c8eae61-703b-4bf2-8a6a-b63d3a8f915f"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["mlm_Y_hat\n"," tensor([[[-0.4304,  0.0563,  0.1566,  ...,  0.3092, -0.6604,  0.2908],\n","         [-0.7362, -0.3627, -0.5952,  ...,  0.1633,  0.0603,  0.2548],\n","         [-0.9460, -0.3693,  0.1905,  ...,  0.3316,  0.3007, -0.4621]],\n","\n","        [[-0.5851, -0.3564, -0.7247,  ...,  0.6641, -0.1380,  0.2987],\n","         [-0.0319, -0.0562,  0.1862,  ...,  0.2184, -0.1564,  0.5300],\n","         [-0.3912,  0.1816, -0.0865,  ..., -0.3465,  0.6715,  1.2724]]],\n","       grad_fn=<AddBackward0>)\n","mlm_Y_hat shape\n"," torch.Size([2, 3, 10000])\n","---------------------------------------\n","mlm_Y\n"," tensor([[ 7,  8,  9],\n","        [10, 20, 30]])\n","mlm_Y shape\n"," torch.Size([2, 3])\n","---------------------------------------\n","<mlm_Y_hat.reshape(-1, vocab_size).shape>\n"," torch.Size([6, 10000])\n","<mlm_Y.reshape(-1).shape>\n"," torch.Size([6])\n"]}]},{"cell_type":"code","source":["print(\"<mlm_loss>\\n\", mlm_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6p2J1dFJQo8t","executionInfo":{"status":"ok","timestamp":1644214228891,"user_tz":-540,"elapsed":2,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"38eb67cb-2c67-4873-dc97-52fe82732018"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["<mlm_loss>\n"," tensor([ 8.6584, 10.2194,  8.6143,  8.1596,  9.4520,  9.9685],\n","       grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"code","source":["class NextSentencePred(nn.Module):\n","    \"\"\"The next sentence prediction task of BERT.\"\"\"\n","    def __init__(self, num_inputs, **kwargs):\n","        super(NextSentencePred, self).__init__(**kwargs)\n","        self.output = nn.Linear(num_inputs, 2)\n","\n","    def forward(self, X):\n","        # `X` shape: (batch size, `num_hiddens`)\n","        return self.output(X)"],"metadata":{"id":"5YO6Mi2myNSS","executionInfo":{"status":"ok","timestamp":1644214231566,"user_tz":-540,"elapsed":317,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["print(\"encoded_X.shape\\n\", encoded_X.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CFIffBSzij2","executionInfo":{"status":"ok","timestamp":1644214242763,"user_tz":-540,"elapsed":462,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"7d9a70f1-14e0-42b2-bfc5-6fe322e54bf7"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 8, 768])"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["# PyTorch by default won't flatten the tensor as seen in mxnet where, if\n","# flatten=True, all but the first axis of input data are collapsed together\n","encoded_X = torch.flatten(encoded_X, start_dim=1)\n","print(\"<encoded_X.shape>\\n\", encoded_X.shape)\n","print(\"--------------------------------------\")\n","\n","print(\"<encoded_X.shape[-1]>\\n\", encoded_X.shape[-1])\n","# input_shape for NSP: (batch size, `num_hiddens`)\n","nsp = NextSentencePred(encoded_X.shape[-1]) # encoded_X.shape[-1] == 6144\n","print(\"--------------------------------------\")\n","\n","nsp_Y_hat = nsp.forward(encoded_X)  # encoded_X==2,6144 --> NSP --> nsp_Y_hat==2,2\n","print(\"<nsp_Y_hat.shape>\\n\", nsp_Y_hat.shape)\n","print(\"<nsp_Y_hat>\\n\", nsp_Y_hat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mweMhXo8y5j6","executionInfo":{"status":"ok","timestamp":1644217122210,"user_tz":-540,"elapsed":323,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"a21e68ae-24db-42c2-8286-cb0c64e24db4"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["<encoded_X.shape>\n"," torch.Size([2, 6144])\n","--------------------------------------\n","<encoded_X.shape[-1]>\n"," 6144\n","--------------------------------------\n","<nsp_Y_hat.shape>\n"," torch.Size([2, 2])\n","<nsp_Y_hat>\n"," tensor([[-1.1725,  1.3185],\n","        [-0.5727,  1.4521]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["nsp_y = torch.tensor([0, 1])\n","\n","nsp_loss = loss(nsp_Y_hat, nsp_y)\n","print(\"<nsp_loss>\\n\", nsp_loss)\n","print(\"<nsp_loss.shape>\\n\", nsp_loss.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VL7M4SXzuSz","executionInfo":{"status":"ok","timestamp":1644217040886,"user_tz":-540,"elapsed":427,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}},"outputId":"5c125663-4799-4db9-c206-ecde995669fb"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["<nsp_loss>\n"," tensor([0.2549, 1.0724], grad_fn=<NllLossBackward0>)\n","<nsp_loss.shape>\n"," torch.Size([2])\n"]}]},{"cell_type":"code","source":["class BERTModel(nn.Module):\n","    \"\"\"The BERT model.\"\"\"\n","    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n","                 ffn_num_hiddens, num_heads, num_layers, dropout,\n","                 max_len=1000, key_size=768, query_size=768, value_size=768,\n","                 hid_in_features=768, mlm_in_features=768,\n","                 nsp_in_features=768):\n","        super(BERTModel, self).__init__()\n","        self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape,\n","                    ffn_num_input, ffn_num_hiddens, num_heads, num_layers,\n","                    dropout, max_len=max_len, key_size=key_size,\n","                    query_size=query_size, value_size=value_size)\n","        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n","                                    nn.Tanh())\n","        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n","        self.nsp = NextSentencePred(nsp_in_features)\n","\n","    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):\n","        encoded_X = self.encoder(tokens, segments, valid_lens)\n","        if pred_positions is not None:\n","            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n","        else:\n","            mlm_Y_hat = None\n","        # The hidden layer of the MLP classifier for next sentence prediction.\n","        # 0 is the index of the '<cls>' token\n","        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n","        return encoded_X, mlm_Y_hat, nsp_Y_hat"],"metadata":{"id":"wa4JSJ379_8W","executionInfo":{"status":"ok","timestamp":1644218350979,"user_tz":-540,"elapsed":314,"user":{"displayName":"J Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14707665891089999345"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"kAKFR6GMDPpI"},"execution_count":null,"outputs":[]}]}